<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head></head><body>





















    
    
    
    

  <div class="border-box-sizing">
    <div class="container">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4>Step1. data preprocessing</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#load the dataset ratings</span>
<span class="n">original_ratings_df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;E:/MyCourses/CSC478ProgrammingMachineLearning/finalProject/moviedata/ratings.csv&quot;</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
<span class="n">original_ratings_df</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[2]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userId</th>
      <th>movieId</th>
      <th>rating</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>4.0</td>
      <td>964982703</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>3</td>
      <td>4.0</td>
      <td>964981247</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>6</td>
      <td>4.0</td>
      <td>964982224</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>47</td>
      <td>5.0</td>
      <td>964983815</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>50</td>
      <td>5.0</td>
      <td>964982931</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>100831</th>
      <td>610</td>
      <td>166534</td>
      <td>4.0</td>
      <td>1493848402</td>
    </tr>
    <tr>
      <th>100832</th>
      <td>610</td>
      <td>168248</td>
      <td>5.0</td>
      <td>1493850091</td>
    </tr>
    <tr>
      <th>100833</th>
      <td>610</td>
      <td>168250</td>
      <td>5.0</td>
      <td>1494273047</td>
    </tr>
    <tr>
      <th>100834</th>
      <td>610</td>
      <td>168252</td>
      <td>5.0</td>
      <td>1493846352</td>
    </tr>
    <tr>
      <th>100835</th>
      <td>610</td>
      <td>170875</td>
      <td>3.0</td>
      <td>1493846415</td>
    </tr>
  </tbody>
</table>
<p>100836 rows &#215; 4 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#load the dataset movies</span>
<span class="n">movies_df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;E:/MyCourses/CSC478ProgrammingMachineLearning/finalProject/moviedata/movies.csv&quot;</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">movies_df</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[3]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>genres</th>
    </tr>
    <tr>
      <th>movieId</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>Toy Story (1995)</td>
      <td>Adventure|Animation|Children|Comedy|Fantasy</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Jumanji (1995)</td>
      <td>Adventure|Children|Fantasy</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Grumpier Old Men (1995)</td>
      <td>Comedy|Romance</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Waiting to Exhale (1995)</td>
      <td>Comedy|Drama|Romance</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Father of the Bride Part II (1995)</td>
      <td>Comedy</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>193581</th>
      <td>Black Butler: Book of the Atlantic (2017)</td>
      <td>Action|Animation|Comedy|Fantasy</td>
    </tr>
    <tr>
      <th>193583</th>
      <td>No Game No Life: Zero (2017)</td>
      <td>Animation|Comedy|Fantasy</td>
    </tr>
    <tr>
      <th>193585</th>
      <td>Flint (2017)</td>
      <td>Drama</td>
    </tr>
    <tr>
      <th>193587</th>
      <td>Bungo Stray Dogs: Dead Apple (2018)</td>
      <td>Action|Animation</td>
    </tr>
    <tr>
      <th>193609</th>
      <td>Andrew Dice Clay: Dice Rules (1991)</td>
      <td>Comedy</td>
    </tr>
  </tbody>
</table>
<p>9742 rows &#215; 2 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">user_num</span><span class="o">=</span><span class="n">original_ratings_df</span><span class="o">.</span><span class="n">userId</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;user_num: &#39;</span><span class="p">,</span><span class="n">user_num</span><span class="p">)</span>
<span class="n">movie_num</span><span class="o">=</span><span class="n">original_ratings_df</span><span class="o">.</span><span class="n">movieId</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;movie_num: &#39;</span><span class="p">,</span><span class="n">movie_num</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>user_num:  610
movie_num:  9724
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">user_header</span><span class="o">=</span><span class="n">original_ratings_df</span><span class="o">.</span><span class="n">userId</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="n">movie_index</span><span class="o">=</span><span class="n">original_ratings_df</span><span class="o">.</span><span class="n">movieId</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#recreate a ratings dataset, let the header be userId and index be movieId</span>
<span class="n">ratings_data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">movie_num</span><span class="p">,</span><span class="n">user_num</span><span class="p">))</span>
<span class="n">ratings_data</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[6]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">ratings_df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">ratings_data</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">movie_index</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="n">user_header</span><span class="p">)</span>
<span class="n">ratings_df</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[7]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>...</th>
      <th>601</th>
      <th>602</th>
      <th>603</th>
      <th>604</th>
      <th>605</th>
      <th>606</th>
      <th>607</th>
      <th>608</th>
      <th>609</th>
      <th>610</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>47</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>50</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>160341</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>160527</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>160836</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>163937</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>163981</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>9724 rows &#215; 610 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#fill the original data to the new dataframe, 0.0 means the user didn&#39;t rate the movie</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span><span class="n">row</span> <span class="ow">in</span> <span class="n">original_ratings_df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">r</span><span class="o">=</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;movieId&#39;</span><span class="p">]</span>
    <span class="n">c</span><span class="o">=</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;userId&#39;</span><span class="p">]</span>
    <span class="n">ratings_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">r</span><span class="p">,</span><span class="n">c</span><span class="p">]</span><span class="o">=</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;rating&#39;</span><span class="p">]</span>
<span class="n">ratings_df</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[8]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>...</th>
      <th>601</th>
      <th>602</th>
      <th>603</th>
      <th>604</th>
      <th>605</th>
      <th>606</th>
      <th>607</th>
      <th>608</th>
      <th>609</th>
      <th>610</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>4.5</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>4.0</td>
      <td>2.5</td>
      <td>4.0</td>
      <td>2.5</td>
      <td>3.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>47</th>
      <td>5.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>4.5</td>
      <td>0.0</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>50</th>
      <td>5.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>4.5</td>
      <td>5.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.5</td>
      <td>0.0</td>
      <td>4.5</td>
      <td>0.0</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>160341</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.5</td>
    </tr>
    <tr>
      <th>160527</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.5</td>
    </tr>
    <tr>
      <th>160836</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>163937</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.5</td>
    </tr>
    <tr>
      <th>163981</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.5</td>
    </tr>
  </tbody>
</table>
<p>9724 rows &#215; 610 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">ratings_arr</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ratings_df</span><span class="p">)</span>
<span class="n">ratings_arr</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[9]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[4. , 0. , 0. , ..., 2.5, 3. , 5. ],
       [4. , 0. , 0. , ..., 2. , 0. , 0. ],
       [4. , 0. , 0. , ..., 0. , 0. , 5. ],
       ...,
       [0. , 0. , 0. , ..., 0. , 0. , 3. ],
       [0. , 0. , 0. , ..., 0. , 0. , 3.5],
       [0. , 0. , 0. , ..., 0. , 0. , 3.5]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#did_ratings_arr is used to decide whether a certain movie is rated by a certain user</span>
<span class="n">did_ratings_arr</span><span class="o">=</span><span class="p">(</span><span class="n">ratings_arr</span><span class="o">!=</span><span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="mi">1</span>
<span class="n">did_ratings_arr</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[10]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[1, 0, 0, ..., 1, 1, 1],
       [1, 0, 0, ..., 1, 0, 0],
       [1, 0, 0, ..., 0, 0, 1],
       ...,
       [0, 0, 0, ..., 0, 0, 1],
       [0, 0, 0, ..., 0, 0, 1],
       [0, 0, 0, ..., 0, 0, 1]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">ratings_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">true_divide</span><span class="p">(</span><span class="n">ratings_arr</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">),(</span><span class="n">ratings_arr</span><span class="o">!=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">ratings_mean</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[11]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([3.92093023, 3.25961538, 3.94607843, ..., 3.        , 3.5       ,
       3.5       ])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">ratings_mean_df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">ratings_mean</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">movie_index</span><span class="p">)</span>
<span class="n">ratings_mean_df</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[12]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>3.920930</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3.259615</td>
    </tr>
    <tr>
      <th>6</th>
      <td>3.946078</td>
    </tr>
    <tr>
      <th>47</th>
      <td>3.975369</td>
    </tr>
    <tr>
      <th>50</th>
      <td>4.237745</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>160341</th>
      <td>2.500000</td>
    </tr>
    <tr>
      <th>160527</th>
      <td>4.500000</td>
    </tr>
    <tr>
      <th>160836</th>
      <td>3.000000</td>
    </tr>
    <tr>
      <th>163937</th>
      <td>3.500000</td>
    </tr>
    <tr>
      <th>163981</th>
      <td>3.500000</td>
    </tr>
  </tbody>
</table>
<p>9724 rows &#215; 1 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4>Step2. generate movie features and user preferences</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#choose a certain movie features count</span>
<span class="n">movie_feature_num</span><span class="o">=</span><span class="mi">5</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#randomly generate movie features and user preferences</span>
<span class="c1">#then we will use gradient descent to approach the optimal value</span>
<span class="n">movie_feature_arr</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">movie_num</span><span class="p">,</span><span class="n">movie_feature_num</span><span class="p">)</span>
<span class="n">user_prefs</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">user_num</span><span class="p">,</span><span class="n">movie_feature_num</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">movie_feature_arr</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[15]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[ 0.08673071, -1.45623762, -0.71690811,  0.56940428,  0.28418335],
       [-0.68504023, -0.01171159,  0.75376497,  0.10164719, -0.9297926 ],
       [-1.43187839,  2.16844113,  0.72058785,  1.39500807,  0.08944791],
       ...,
       [ 0.63006556,  0.7745833 ,  0.08989993,  0.17261859, -1.61911515],
       [ 0.64037755, -0.56444658,  0.59562773, -0.70006365, -1.45717613],
       [-0.64378512,  0.49655951,  0.6571958 , -0.38178866,  0.72763484]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#this method is from class example.</span>
<span class="k">def</span> <span class="nf">matrix_factorization</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.002</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.002</span><span class="p">):</span>
    <span class="c1">### R = The user x item rating matrix (m x n)</span>
    <span class="c1">### P = Initial user-preference matrix (m x k)</span>
    <span class="c1">### Q = Initial movie-features matrix (n x k)</span>
    <span class="c1">### K = The number of features</span>
    <span class="c1">### steps = The number of epochs in gradient descent</span>
    <span class="c1">### alpha = The learning rate for gradient descent</span>
    <span class="c1">### beta = The regularization coefficient</span>
    <span class="n">Q</span> <span class="o">=</span> <span class="n">Q</span><span class="o">.</span><span class="n">T</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">R</span><span class="p">)):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">R</span><span class="p">[</span><span class="n">i</span><span class="p">])):</span>
                <span class="k">if</span> <span class="n">R</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">eij</span> <span class="o">=</span> <span class="n">R</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="p">,:],</span><span class="n">Q</span><span class="p">[:,</span><span class="n">j</span><span class="p">])</span>
                    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
                        <span class="c1">### update P and Q based on the partial derivatives of the loss function</span>
                        <span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">eij</span> <span class="o">*</span> <span class="n">Q</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">])</span>
                        <span class="n">Q</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">eij</span> <span class="o">*</span> <span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">Q</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">])</span>
        <span class="n">e</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">R</span><span class="p">)):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">R</span><span class="p">[</span><span class="n">i</span><span class="p">])):</span>
                <span class="k">if</span> <span class="n">R</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">e</span> <span class="o">=</span> <span class="n">e</span> <span class="o">+</span> <span class="nb">pow</span><span class="p">(</span><span class="n">R</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="p">,:],</span><span class="n">Q</span><span class="p">[:,</span><span class="n">j</span><span class="p">]),</span> <span class="mi">2</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
                        <span class="n">e</span> <span class="o">=</span> <span class="n">e</span> <span class="o">+</span> <span class="p">(</span><span class="n">beta</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span> <span class="nb">pow</span><span class="p">(</span><span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="nb">pow</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span> <span class="p">)</span>
        <span class="n">e</span><span class="o">=</span><span class="n">e</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">e</span> <span class="o">&lt;</span> <span class="mf">0.1</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Step </span><span class="si">%d</span><span class="s2"> of </span><span class="si">%d</span><span class="s2">; Error: </span><span class="si">%0.5f</span><span class="s2">; Time: </span><span class="si">%0.2f</span><span class="s2">&quot;</span> <span class="o">%</span><span class="p">(</span><span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">time</span><span class="p">()))</span>
    <span class="k">return</span> <span class="n">P</span><span class="p">,</span> <span class="n">Q</span><span class="o">.</span><span class="n">T</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>
<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">matrix_factorization</span><span class="p">(</span><span class="n">ratings_data</span><span class="p">,</span><span class="n">movie_feature_arr</span><span class="p">,</span><span class="n">user_prefs</span><span class="p">,</span><span class="n">movie_feature_num</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;done in </span><span class="si">%0.3f</span><span class="s2">s.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Step 1 of 1000; Error: 13.39324; Time: 1591635454.54
Step 2 of 1000; Error: 9.97003; Time: 1591635462.57
Step 3 of 1000; Error: 6.25768; Time: 1591635470.59
Step 4 of 1000; Error: 4.57641; Time: 1591635478.64
Step 5 of 1000; Error: 3.67174; Time: 1591635486.74
Step 6 of 1000; Error: 3.09695; Time: 1591635494.80
Step 7 of 1000; Error: 2.69273; Time: 1591635503.01
Step 8 of 1000; Error: 2.38989; Time: 1591635511.23
Step 9 of 1000; Error: 2.15368; Time: 1591635519.27
Step 10 of 1000; Error: 1.96441; Time: 1591635527.40
Step 11 of 1000; Error: 1.80978; Time: 1591635535.49
Step 12 of 1000; Error: 1.68161; Time: 1591635543.64
Step 13 of 1000; Error: 1.57409; Time: 1591635551.72
Step 14 of 1000; Error: 1.48299; Time: 1591635559.80
Step 15 of 1000; Error: 1.40511; Time: 1591635568.10
Step 16 of 1000; Error: 1.33796; Time: 1591635576.57
Step 17 of 1000; Error: 1.27962; Time: 1591635584.82
Step 18 of 1000; Error: 1.22853; Time: 1591635593.24
Step 19 of 1000; Error: 1.18347; Time: 1591635604.62
Step 20 of 1000; Error: 1.14344; Time: 1591635617.32
Step 21 of 1000; Error: 1.10761; Time: 1591635631.16
Step 22 of 1000; Error: 1.07534; Time: 1591635640.19
Step 23 of 1000; Error: 1.04607; Time: 1591635648.78
Step 24 of 1000; Error: 1.01936; Time: 1591635658.26
Step 25 of 1000; Error: 0.99483; Time: 1591635671.23
Step 26 of 1000; Error: 0.97221; Time: 1591635683.59
Step 27 of 1000; Error: 0.95122; Time: 1591635694.57
Step 28 of 1000; Error: 0.93168; Time: 1591635703.25
Step 29 of 1000; Error: 0.91342; Time: 1591635711.89
Step 30 of 1000; Error: 0.89629; Time: 1591635721.92
Step 31 of 1000; Error: 0.88018; Time: 1591635730.56
Step 32 of 1000; Error: 0.86501; Time: 1591635739.09
Step 33 of 1000; Error: 0.85068; Time: 1591635757.28
Step 34 of 1000; Error: 0.83714; Time: 1591635768.14
Step 35 of 1000; Error: 0.82433; Time: 1591635779.11
Step 36 of 1000; Error: 0.81219; Time: 1591635790.82
Step 37 of 1000; Error: 0.80068; Time: 1591635799.29
Step 38 of 1000; Error: 0.78978; Time: 1591635807.92
Step 39 of 1000; Error: 0.77943; Time: 1591635816.71
Step 40 of 1000; Error: 0.76961; Time: 1591635825.64
Step 41 of 1000; Error: 0.76030; Time: 1591635834.53
Step 42 of 1000; Error: 0.75146; Time: 1591635843.13
Step 43 of 1000; Error: 0.74306; Time: 1591635851.64
Step 44 of 1000; Error: 0.73510; Time: 1591635860.12
Step 45 of 1000; Error: 0.72753; Time: 1591635881.57
Step 46 of 1000; Error: 0.72035; Time: 1591635896.98
Step 47 of 1000; Error: 0.71353; Time: 1591635908.87
Step 48 of 1000; Error: 0.70704; Time: 1591635917.74
Step 49 of 1000; Error: 0.70089; Time: 1591635926.62
Step 50 of 1000; Error: 0.69503; Time: 1591635935.37
Step 51 of 1000; Error: 0.68947; Time: 1591635944.08
Step 52 of 1000; Error: 0.68418; Time: 1591635952.80
Step 53 of 1000; Error: 0.67915; Time: 1591635961.73
Step 54 of 1000; Error: 0.67436; Time: 1591635970.52
Step 55 of 1000; Error: 0.66980; Time: 1591635979.11
Step 56 of 1000; Error: 0.66545; Time: 1591635987.87
Step 57 of 1000; Error: 0.66132; Time: 1591635996.49
Step 58 of 1000; Error: 0.65737; Time: 1591636005.18
Step 59 of 1000; Error: 0.65361; Time: 1591636013.92
Step 60 of 1000; Error: 0.65002; Time: 1591636022.88
Step 61 of 1000; Error: 0.64659; Time: 1591636031.93
Step 62 of 1000; Error: 0.64332; Time: 1591636040.91
Step 63 of 1000; Error: 0.64019; Time: 1591636049.85
Step 64 of 1000; Error: 0.63720; Time: 1591636058.79
Step 65 of 1000; Error: 0.63433; Time: 1591636067.79
Step 66 of 1000; Error: 0.63159; Time: 1591636078.23
Step 67 of 1000; Error: 0.62897; Time: 1591636095.88
Step 68 of 1000; Error: 0.62645; Time: 1591636104.94
Step 69 of 1000; Error: 0.62403; Time: 1591636115.20
Step 70 of 1000; Error: 0.62172; Time: 1591636125.94
Step 71 of 1000; Error: 0.61949; Time: 1591636136.66
Step 72 of 1000; Error: 0.61735; Time: 1591636146.51
Step 73 of 1000; Error: 0.61530; Time: 1591636156.64
Step 74 of 1000; Error: 0.61332; Time: 1591636168.41
Step 75 of 1000; Error: 0.61141; Time: 1591636180.99
Step 76 of 1000; Error: 0.60958; Time: 1591636191.25
Step 77 of 1000; Error: 0.60781; Time: 1591636201.36
Step 78 of 1000; Error: 0.60610; Time: 1591636210.80
Step 79 of 1000; Error: 0.60446; Time: 1591636220.35
Step 80 of 1000; Error: 0.60287; Time: 1591636232.86
Step 81 of 1000; Error: 0.60133; Time: 1591636242.93
Step 82 of 1000; Error: 0.59985; Time: 1591636252.37
Step 83 of 1000; Error: 0.59841; Time: 1591636263.84
Step 84 of 1000; Error: 0.59702; Time: 1591636273.23
Step 85 of 1000; Error: 0.59567; Time: 1591636284.62
Step 86 of 1000; Error: 0.59436; Time: 1591636295.67
Step 87 of 1000; Error: 0.59309; Time: 1591636307.19
Step 88 of 1000; Error: 0.59186; Time: 1591636316.59
Step 89 of 1000; Error: 0.59066; Time: 1591636326.03
Step 90 of 1000; Error: 0.58950; Time: 1591636335.34
Step 91 of 1000; Error: 0.58837; Time: 1591636344.75
Step 92 of 1000; Error: 0.58727; Time: 1591636354.14
Step 93 of 1000; Error: 0.58620; Time: 1591636364.47
Step 94 of 1000; Error: 0.58516; Time: 1591636375.01
Step 95 of 1000; Error: 0.58414; Time: 1591636384.77
Step 96 of 1000; Error: 0.58315; Time: 1591636394.62
Step 97 of 1000; Error: 0.58218; Time: 1591636404.19
Step 98 of 1000; Error: 0.58124; Time: 1591636413.73
Step 99 of 1000; Error: 0.58031; Time: 1591636423.62
Step 100 of 1000; Error: 0.57941; Time: 1591636433.23
Step 101 of 1000; Error: 0.57853; Time: 1591636442.57
Step 102 of 1000; Error: 0.57766; Time: 1591636452.02
Step 103 of 1000; Error: 0.57681; Time: 1591636461.38
Step 104 of 1000; Error: 0.57598; Time: 1591636471.25
Step 105 of 1000; Error: 0.57517; Time: 1591636481.77
Step 106 of 1000; Error: 0.57437; Time: 1591636491.37
Step 107 of 1000; Error: 0.57359; Time: 1591636501.06
Step 108 of 1000; Error: 0.57282; Time: 1591636509.55
Step 109 of 1000; Error: 0.57207; Time: 1591636518.30
Step 110 of 1000; Error: 0.57133; Time: 1591636526.84
Step 111 of 1000; Error: 0.57060; Time: 1591636535.42
Step 112 of 1000; Error: 0.56988; Time: 1591636543.92
Step 113 of 1000; Error: 0.56918; Time: 1591636556.01
Step 114 of 1000; Error: 0.56848; Time: 1591636569.18
Step 115 of 1000; Error: 0.56780; Time: 1591636582.24
Step 116 of 1000; Error: 0.56712; Time: 1591636590.80
Step 117 of 1000; Error: 0.56646; Time: 1591636599.50
Step 118 of 1000; Error: 0.56581; Time: 1591636608.04
Step 119 of 1000; Error: 0.56516; Time: 1591636616.56
Step 120 of 1000; Error: 0.56452; Time: 1591636625.28
Step 121 of 1000; Error: 0.56390; Time: 1591636633.86
Step 122 of 1000; Error: 0.56328; Time: 1591636642.34
Step 123 of 1000; Error: 0.56266; Time: 1591636650.89
Step 124 of 1000; Error: 0.56206; Time: 1591636659.35
Step 125 of 1000; Error: 0.56146; Time: 1591636667.92
Step 126 of 1000; Error: 0.56087; Time: 1591636676.49
Step 127 of 1000; Error: 0.56029; Time: 1591636685.17
Step 128 of 1000; Error: 0.55971; Time: 1591636694.26
Step 129 of 1000; Error: 0.55914; Time: 1591636702.74
Step 130 of 1000; Error: 0.55857; Time: 1591636711.37
Step 131 of 1000; Error: 0.55801; Time: 1591636719.68
Step 132 of 1000; Error: 0.55746; Time: 1591636728.19
Step 133 of 1000; Error: 0.55691; Time: 1591636736.76
Step 134 of 1000; Error: 0.55637; Time: 1591636745.41
Step 135 of 1000; Error: 0.55583; Time: 1591636754.35
Step 136 of 1000; Error: 0.55530; Time: 1591636763.24
Step 137 of 1000; Error: 0.55477; Time: 1591636772.36
Step 138 of 1000; Error: 0.55425; Time: 1591636781.38
Step 139 of 1000; Error: 0.55373; Time: 1591636790.01
Step 140 of 1000; Error: 0.55321; Time: 1591636798.62
Step 141 of 1000; Error: 0.55270; Time: 1591636807.45
Step 142 of 1000; Error: 0.55220; Time: 1591636815.86
Step 143 of 1000; Error: 0.55170; Time: 1591636827.51
Step 144 of 1000; Error: 0.55120; Time: 1591636839.71
Step 145 of 1000; Error: 0.55071; Time: 1591636848.54
Step 146 of 1000; Error: 0.55022; Time: 1591636857.46
Step 147 of 1000; Error: 0.54973; Time: 1591636867.92
Step 148 of 1000; Error: 0.54925; Time: 1591636878.08
Step 149 of 1000; Error: 0.54877; Time: 1591636888.31
Step 150 of 1000; Error: 0.54829; Time: 1591636899.67
Step 151 of 1000; Error: 0.54782; Time: 1591636910.21
Step 152 of 1000; Error: 0.54735; Time: 1591636918.99
Step 153 of 1000; Error: 0.54689; Time: 1591636927.48
Step 154 of 1000; Error: 0.54643; Time: 1591636936.02
Step 155 of 1000; Error: 0.54597; Time: 1591636944.62
Step 156 of 1000; Error: 0.54551; Time: 1591636953.33
Step 157 of 1000; Error: 0.54506; Time: 1591636961.86
Step 158 of 1000; Error: 0.54461; Time: 1591636970.43
Step 159 of 1000; Error: 0.54416; Time: 1591636979.00
Step 160 of 1000; Error: 0.54372; Time: 1591636987.78
Step 161 of 1000; Error: 0.54328; Time: 1591636996.62
Step 162 of 1000; Error: 0.54284; Time: 1591637005.39
Step 163 of 1000; Error: 0.54240; Time: 1591637014.14
Step 164 of 1000; Error: 0.54197; Time: 1591637023.22
Step 165 of 1000; Error: 0.54154; Time: 1591637032.07
Step 166 of 1000; Error: 0.54111; Time: 1591637041.35
Step 167 of 1000; Error: 0.54069; Time: 1591637050.81
Step 168 of 1000; Error: 0.54026; Time: 1591637060.05
Step 169 of 1000; Error: 0.53984; Time: 1591637069.18
Step 170 of 1000; Error: 0.53943; Time: 1591637078.32
Step 171 of 1000; Error: 0.53901; Time: 1591637087.19
Step 172 of 1000; Error: 0.53860; Time: 1591637096.02
Step 173 of 1000; Error: 0.53819; Time: 1591637104.65
Step 174 of 1000; Error: 0.53778; Time: 1591637113.89
Step 175 of 1000; Error: 0.53737; Time: 1591637124.26
Step 176 of 1000; Error: 0.53697; Time: 1591637133.36
Step 177 of 1000; Error: 0.53657; Time: 1591637142.76
Step 178 of 1000; Error: 0.53617; Time: 1591637154.05
Step 179 of 1000; Error: 0.53577; Time: 1591637162.80
Step 180 of 1000; Error: 0.53537; Time: 1591637171.31
Step 181 of 1000; Error: 0.53498; Time: 1591637180.22
Step 182 of 1000; Error: 0.53459; Time: 1591637191.03
Step 183 of 1000; Error: 0.53420; Time: 1591637203.90
Step 184 of 1000; Error: 0.53381; Time: 1591637216.33
Step 185 of 1000; Error: 0.53343; Time: 1591637224.99
Step 186 of 1000; Error: 0.53305; Time: 1591637233.58
Step 187 of 1000; Error: 0.53267; Time: 1591637243.18
Step 188 of 1000; Error: 0.53229; Time: 1591637253.92
Step 189 of 1000; Error: 0.53191; Time: 1591637262.68
Step 190 of 1000; Error: 0.53153; Time: 1591637271.32
Step 191 of 1000; Error: 0.53116; Time: 1591637280.06
Step 192 of 1000; Error: 0.53079; Time: 1591637288.74
Step 193 of 1000; Error: 0.53042; Time: 1591637297.33
Step 194 of 1000; Error: 0.53005; Time: 1591637305.99
Step 195 of 1000; Error: 0.52969; Time: 1591637314.64
Step 196 of 1000; Error: 0.52932; Time: 1591637323.27
Step 197 of 1000; Error: 0.52896; Time: 1591637332.03
Step 198 of 1000; Error: 0.52860; Time: 1591637340.69
Step 199 of 1000; Error: 0.52824; Time: 1591637349.62
Step 200 of 1000; Error: 0.52788; Time: 1591637358.13
Step 201 of 1000; Error: 0.52753; Time: 1591637366.72
Step 202 of 1000; Error: 0.52717; Time: 1591637375.26
Step 203 of 1000; Error: 0.52682; Time: 1591637383.86
Step 204 of 1000; Error: 0.52647; Time: 1591637392.44
Step 205 of 1000; Error: 0.52612; Time: 1591637401.13
Step 206 of 1000; Error: 0.52578; Time: 1591637409.69
Step 207 of 1000; Error: 0.52543; Time: 1591637418.46
Step 208 of 1000; Error: 0.52509; Time: 1591637428.13
Step 209 of 1000; Error: 0.52474; Time: 1591637437.70
Step 210 of 1000; Error: 0.52440; Time: 1591637446.49
Step 211 of 1000; Error: 0.52406; Time: 1591637455.88
Step 212 of 1000; Error: 0.52373; Time: 1591637464.52
Step 213 of 1000; Error: 0.52339; Time: 1591637473.23
Step 214 of 1000; Error: 0.52306; Time: 1591637482.27
Step 215 of 1000; Error: 0.52272; Time: 1591637490.90
Step 216 of 1000; Error: 0.52239; Time: 1591637499.62
Step 217 of 1000; Error: 0.52206; Time: 1591637507.94
Step 218 of 1000; Error: 0.52173; Time: 1591637516.19
Step 219 of 1000; Error: 0.52140; Time: 1591637524.58
Step 220 of 1000; Error: 0.52108; Time: 1591637532.91
Step 221 of 1000; Error: 0.52075; Time: 1591637541.29
Step 222 of 1000; Error: 0.52043; Time: 1591637550.01
Step 223 of 1000; Error: 0.52011; Time: 1591637558.44
Step 224 of 1000; Error: 0.51979; Time: 1591637566.77
Step 225 of 1000; Error: 0.51947; Time: 1591637575.03
Step 226 of 1000; Error: 0.51915; Time: 1591637583.27
Step 227 of 1000; Error: 0.51884; Time: 1591637591.62
Step 228 of 1000; Error: 0.51852; Time: 1591637599.88
Step 229 of 1000; Error: 0.51821; Time: 1591637608.16
Step 230 of 1000; Error: 0.51790; Time: 1591637616.71
Step 231 of 1000; Error: 0.51758; Time: 1591637624.96
Step 232 of 1000; Error: 0.51727; Time: 1591637633.28
Step 233 of 1000; Error: 0.51697; Time: 1591637641.94
Step 234 of 1000; Error: 0.51666; Time: 1591637650.58
Step 235 of 1000; Error: 0.51635; Time: 1591637658.89
Step 236 of 1000; Error: 0.51605; Time: 1591637667.25
Step 237 of 1000; Error: 0.51575; Time: 1591637675.79
Step 238 of 1000; Error: 0.51544; Time: 1591637684.24
Step 239 of 1000; Error: 0.51514; Time: 1591637692.54
Step 240 of 1000; Error: 0.51484; Time: 1591637700.85
Step 241 of 1000; Error: 0.51455; Time: 1591637709.15
Step 242 of 1000; Error: 0.51425; Time: 1591637717.47
Step 243 of 1000; Error: 0.51395; Time: 1591637725.83
Step 244 of 1000; Error: 0.51366; Time: 1591637734.13
Step 245 of 1000; Error: 0.51336; Time: 1591637742.53
Step 246 of 1000; Error: 0.51307; Time: 1591637750.91
Step 247 of 1000; Error: 0.51278; Time: 1591637759.24
Step 248 of 1000; Error: 0.51249; Time: 1591637767.57
Step 249 of 1000; Error: 0.51220; Time: 1591637775.81
Step 250 of 1000; Error: 0.51191; Time: 1591637784.10
Step 251 of 1000; Error: 0.51163; Time: 1591637792.36
Step 252 of 1000; Error: 0.51134; Time: 1591637800.68
Step 253 of 1000; Error: 0.51106; Time: 1591637809.18
Step 254 of 1000; Error: 0.51077; Time: 1591637817.60
Step 255 of 1000; Error: 0.51049; Time: 1591637825.93
Step 256 of 1000; Error: 0.51021; Time: 1591637834.18
Step 257 of 1000; Error: 0.50993; Time: 1591637842.40
Step 258 of 1000; Error: 0.50965; Time: 1591637850.74
Step 259 of 1000; Error: 0.50937; Time: 1591637858.99
Step 260 of 1000; Error: 0.50909; Time: 1591637867.29
Step 261 of 1000; Error: 0.50882; Time: 1591637875.82
Step 262 of 1000; Error: 0.50854; Time: 1591637884.08
Step 263 of 1000; Error: 0.50827; Time: 1591637892.35
Step 264 of 1000; Error: 0.50800; Time: 1591637900.60
Step 265 of 1000; Error: 0.50772; Time: 1591637908.93
Step 266 of 1000; Error: 0.50745; Time: 1591637917.35
Step 267 of 1000; Error: 0.50718; Time: 1591637925.87
Step 268 of 1000; Error: 0.50691; Time: 1591637934.15
Step 269 of 1000; Error: 0.50665; Time: 1591637942.79
Step 270 of 1000; Error: 0.50638; Time: 1591637951.08
Step 271 of 1000; Error: 0.50611; Time: 1591637959.44
Step 272 of 1000; Error: 0.50585; Time: 1591637967.75
Step 273 of 1000; Error: 0.50558; Time: 1591637976.05
Step 274 of 1000; Error: 0.50532; Time: 1591637984.29
Step 275 of 1000; Error: 0.50506; Time: 1591637992.66
Step 276 of 1000; Error: 0.50480; Time: 1591638000.90
Step 277 of 1000; Error: 0.50454; Time: 1591638009.46
Step 278 of 1000; Error: 0.50428; Time: 1591638017.73
Step 279 of 1000; Error: 0.50402; Time: 1591638026.11
Step 280 of 1000; Error: 0.50376; Time: 1591638034.52
Step 281 of 1000; Error: 0.50351; Time: 1591638042.91
Step 282 of 1000; Error: 0.50325; Time: 1591638051.16
Step 283 of 1000; Error: 0.50300; Time: 1591638059.48
Step 284 of 1000; Error: 0.50274; Time: 1591638067.71
Step 285 of 1000; Error: 0.50249; Time: 1591638076.33
Step 286 of 1000; Error: 0.50224; Time: 1591638084.68
Step 287 of 1000; Error: 0.50199; Time: 1591638092.91
Step 288 of 1000; Error: 0.50174; Time: 1591638101.23
Step 289 of 1000; Error: 0.50149; Time: 1591638109.43
Step 290 of 1000; Error: 0.50124; Time: 1591638117.79
Step 291 of 1000; Error: 0.50099; Time: 1591638125.99
Step 292 of 1000; Error: 0.50075; Time: 1591638134.38
Step 293 of 1000; Error: 0.50050; Time: 1591638143.18
Step 294 of 1000; Error: 0.50025; Time: 1591638151.56
Step 295 of 1000; Error: 0.50001; Time: 1591638159.90
Step 296 of 1000; Error: 0.49977; Time: 1591638168.23
Step 297 of 1000; Error: 0.49952; Time: 1591638176.60
Step 298 of 1000; Error: 0.49928; Time: 1591638184.91
Step 299 of 1000; Error: 0.49904; Time: 1591638193.15
Step 300 of 1000; Error: 0.49880; Time: 1591638201.48
Step 301 of 1000; Error: 0.49856; Time: 1591638210.36
Step 302 of 1000; Error: 0.49832; Time: 1591638218.81
Step 303 of 1000; Error: 0.49809; Time: 1591638227.05
Step 304 of 1000; Error: 0.49785; Time: 1591638235.35
Step 305 of 1000; Error: 0.49761; Time: 1591638243.65
Step 306 of 1000; Error: 0.49738; Time: 1591638251.95
Step 307 of 1000; Error: 0.49714; Time: 1591638260.23
Step 308 of 1000; Error: 0.49691; Time: 1591638268.49
Step 309 of 1000; Error: 0.49668; Time: 1591638277.09
Step 310 of 1000; Error: 0.49645; Time: 1591638285.40
Step 311 of 1000; Error: 0.49621; Time: 1591638293.79
Step 312 of 1000; Error: 0.49598; Time: 1591638302.02
Step 313 of 1000; Error: 0.49575; Time: 1591638310.32
Step 314 of 1000; Error: 0.49552; Time: 1591638318.70
Step 315 of 1000; Error: 0.49530; Time: 1591638327.09
Step 316 of 1000; Error: 0.49507; Time: 1591638335.51
Step 317 of 1000; Error: 0.49484; Time: 1591638344.02
Step 318 of 1000; Error: 0.49462; Time: 1591638352.32
Step 319 of 1000; Error: 0.49439; Time: 1591638360.73
Step 320 of 1000; Error: 0.49417; Time: 1591638368.95
Step 321 of 1000; Error: 0.49394; Time: 1591638377.26
Step 322 of 1000; Error: 0.49372; Time: 1591638385.45
Step 323 of 1000; Error: 0.49350; Time: 1591638393.82
Step 324 of 1000; Error: 0.49327; Time: 1591638402.26
Step 325 of 1000; Error: 0.49305; Time: 1591638410.78
Step 326 of 1000; Error: 0.49283; Time: 1591638419.08
Step 327 of 1000; Error: 0.49261; Time: 1591638427.39
Step 328 of 1000; Error: 0.49239; Time: 1591638435.69
Step 329 of 1000; Error: 0.49218; Time: 1591638443.95
Step 330 of 1000; Error: 0.49196; Time: 1591638452.31
Step 331 of 1000; Error: 0.49174; Time: 1591638460.57
Step 332 of 1000; Error: 0.49152; Time: 1591638469.12
Step 333 of 1000; Error: 0.49131; Time: 1591638477.43
Step 334 of 1000; Error: 0.49109; Time: 1591638485.74
Step 335 of 1000; Error: 0.49088; Time: 1591638493.96
Step 336 of 1000; Error: 0.49067; Time: 1591638502.33
Step 337 of 1000; Error: 0.49045; Time: 1591638510.53
Step 338 of 1000; Error: 0.49024; Time: 1591638518.81
Step 339 of 1000; Error: 0.49003; Time: 1591638527.01
Step 340 of 1000; Error: 0.48982; Time: 1591638535.56
Step 341 of 1000; Error: 0.48961; Time: 1591638543.94
Step 342 of 1000; Error: 0.48940; Time: 1591638552.17
Step 343 of 1000; Error: 0.48919; Time: 1591638560.37
Step 344 of 1000; Error: 0.48898; Time: 1591638568.67
Step 345 of 1000; Error: 0.48877; Time: 1591638576.91
Step 346 of 1000; Error: 0.48857; Time: 1591638585.32
Step 347 of 1000; Error: 0.48836; Time: 1591638593.65
Step 348 of 1000; Error: 0.48815; Time: 1591638602.15
Step 349 of 1000; Error: 0.48795; Time: 1591638610.50
Step 350 of 1000; Error: 0.48774; Time: 1591638618.84
Step 351 of 1000; Error: 0.48754; Time: 1591638627.07
Step 352 of 1000; Error: 0.48733; Time: 1591638635.39
Step 353 of 1000; Error: 0.48713; Time: 1591638643.76
Step 354 of 1000; Error: 0.48693; Time: 1591638652.14
Step 355 of 1000; Error: 0.48673; Time: 1591638660.51
Step 356 of 1000; Error: 0.48653; Time: 1591638669.00
Step 357 of 1000; Error: 0.48633; Time: 1591638677.36
Step 358 of 1000; Error: 0.48613; Time: 1591638685.57
Step 359 of 1000; Error: 0.48593; Time: 1591638693.86
Step 360 of 1000; Error: 0.48573; Time: 1591638702.20
Step 361 of 1000; Error: 0.48553; Time: 1591638710.58
Step 362 of 1000; Error: 0.48533; Time: 1591638718.89
Step 363 of 1000; Error: 0.48513; Time: 1591638727.11
Step 364 of 1000; Error: 0.48494; Time: 1591638735.61
Step 365 of 1000; Error: 0.48474; Time: 1591638743.97
Step 366 of 1000; Error: 0.48454; Time: 1591638752.28
Step 367 of 1000; Error: 0.48435; Time: 1591638760.58
Step 368 of 1000; Error: 0.48416; Time: 1591638768.87
Step 369 of 1000; Error: 0.48396; Time: 1591638777.19
Step 370 of 1000; Error: 0.48377; Time: 1591638785.44
Step 371 of 1000; Error: 0.48357; Time: 1591638793.74
Step 372 of 1000; Error: 0.48338; Time: 1591638802.40
Step 373 of 1000; Error: 0.48319; Time: 1591638810.72
Step 374 of 1000; Error: 0.48300; Time: 1591638818.98
Step 375 of 1000; Error: 0.48281; Time: 1591638827.33
Step 376 of 1000; Error: 0.48262; Time: 1591638835.67
Step 377 of 1000; Error: 0.48243; Time: 1591638844.05
Step 378 of 1000; Error: 0.48224; Time: 1591638852.33
Step 379 of 1000; Error: 0.48205; Time: 1591638860.59
Step 380 of 1000; Error: 0.48186; Time: 1591638869.21
Step 381 of 1000; Error: 0.48168; Time: 1591638877.53
Step 382 of 1000; Error: 0.48149; Time: 1591638885.80
Step 383 of 1000; Error: 0.48130; Time: 1591638894.03
Step 384 of 1000; Error: 0.48112; Time: 1591638902.45
Step 385 of 1000; Error: 0.48093; Time: 1591638910.81
Step 386 of 1000; Error: 0.48074; Time: 1591638919.09
Step 387 of 1000; Error: 0.48056; Time: 1591638927.35
Step 388 of 1000; Error: 0.48038; Time: 1591638935.89
Step 389 of 1000; Error: 0.48019; Time: 1591638944.08
Step 390 of 1000; Error: 0.48001; Time: 1591638952.33
Step 391 of 1000; Error: 0.47983; Time: 1591638960.60
Step 392 of 1000; Error: 0.47964; Time: 1591638968.89
Step 393 of 1000; Error: 0.47946; Time: 1591638977.17
Step 394 of 1000; Error: 0.47928; Time: 1591638985.56
Step 395 of 1000; Error: 0.47910; Time: 1591638993.93
Step 396 of 1000; Error: 0.47892; Time: 1591639002.58
Step 397 of 1000; Error: 0.47874; Time: 1591639010.79
Step 398 of 1000; Error: 0.47856; Time: 1591639019.14
Step 399 of 1000; Error: 0.47838; Time: 1591639027.52
Step 400 of 1000; Error: 0.47820; Time: 1591639036.10
Step 401 of 1000; Error: 0.47802; Time: 1591639045.36
Step 402 of 1000; Error: 0.47785; Time: 1591639054.64
Step 403 of 1000; Error: 0.47767; Time: 1591639063.24
Step 404 of 1000; Error: 0.47749; Time: 1591639071.90
Step 405 of 1000; Error: 0.47732; Time: 1591639080.51
Step 406 of 1000; Error: 0.47714; Time: 1591639089.00
Step 407 of 1000; Error: 0.47697; Time: 1591639097.62
Step 408 of 1000; Error: 0.47679; Time: 1591639106.20
Step 409 of 1000; Error: 0.47662; Time: 1591639114.81
Step 410 of 1000; Error: 0.47644; Time: 1591639123.48
Step 411 of 1000; Error: 0.47627; Time: 1591639132.36
Step 412 of 1000; Error: 0.47610; Time: 1591639140.86
Step 413 of 1000; Error: 0.47592; Time: 1591639149.21
Step 414 of 1000; Error: 0.47575; Time: 1591639157.76
Step 415 of 1000; Error: 0.47558; Time: 1591639166.35
Step 416 of 1000; Error: 0.47541; Time: 1591639174.96
Step 417 of 1000; Error: 0.47524; Time: 1591639183.48
Step 418 of 1000; Error: 0.47507; Time: 1591639192.10
Step 419 of 1000; Error: 0.47490; Time: 1591639200.90
Step 420 of 1000; Error: 0.47473; Time: 1591639209.54
Step 421 of 1000; Error: 0.47456; Time: 1591639217.98
Step 422 of 1000; Error: 0.47439; Time: 1591639226.65
Step 423 of 1000; Error: 0.47422; Time: 1591639236.71
Step 424 of 1000; Error: 0.47405; Time: 1591639245.20
Step 425 of 1000; Error: 0.47388; Time: 1591639253.91
Step 426 of 1000; Error: 0.47372; Time: 1591639262.83
Step 427 of 1000; Error: 0.47355; Time: 1591639271.51
Step 428 of 1000; Error: 0.47338; Time: 1591639280.16
Step 429 of 1000; Error: 0.47322; Time: 1591639288.91
Step 430 of 1000; Error: 0.47305; Time: 1591639298.07
Step 431 of 1000; Error: 0.47289; Time: 1591639306.60
Step 432 of 1000; Error: 0.47272; Time: 1591639315.10
Step 433 of 1000; Error: 0.47256; Time: 1591639323.69
Step 434 of 1000; Error: 0.47239; Time: 1591639332.54
Step 435 of 1000; Error: 0.47223; Time: 1591639340.99
Step 436 of 1000; Error: 0.47207; Time: 1591639349.62
Step 437 of 1000; Error: 0.47191; Time: 1591639358.19
Step 438 of 1000; Error: 0.47174; Time: 1591639366.80
Step 439 of 1000; Error: 0.47158; Time: 1591639375.58
Step 440 of 1000; Error: 0.47142; Time: 1591639384.46
Step 441 of 1000; Error: 0.47126; Time: 1591639393.33
Step 442 of 1000; Error: 0.47110; Time: 1591639402.25
Step 443 of 1000; Error: 0.47094; Time: 1591639411.35
Step 444 of 1000; Error: 0.47078; Time: 1591639420.47
Step 445 of 1000; Error: 0.47062; Time: 1591639429.74
Step 446 of 1000; Error: 0.47046; Time: 1591639438.44
Step 447 of 1000; Error: 0.47030; Time: 1591639447.14
Step 448 of 1000; Error: 0.47014; Time: 1591639455.77
Step 449 of 1000; Error: 0.46998; Time: 1591639464.93
Step 450 of 1000; Error: 0.46983; Time: 1591639473.50
Step 451 of 1000; Error: 0.46967; Time: 1591639482.07
Step 452 of 1000; Error: 0.46951; Time: 1591639490.71
Step 453 of 1000; Error: 0.46936; Time: 1591639499.37
Step 454 of 1000; Error: 0.46920; Time: 1591639508.35
Step 455 of 1000; Error: 0.46904; Time: 1591639517.00
Step 456 of 1000; Error: 0.46889; Time: 1591639526.64
Step 457 of 1000; Error: 0.46873; Time: 1591639535.69
Step 458 of 1000; Error: 0.46858; Time: 1591639544.71
Step 459 of 1000; Error: 0.46842; Time: 1591639553.24
Step 460 of 1000; Error: 0.46827; Time: 1591639561.85
Step 461 of 1000; Error: 0.46812; Time: 1591639570.45
Step 462 of 1000; Error: 0.46796; Time: 1591639579.00
Step 463 of 1000; Error: 0.46781; Time: 1591639587.49
Step 464 of 1000; Error: 0.46766; Time: 1591639596.25
Step 465 of 1000; Error: 0.46751; Time: 1591639604.81
Step 466 of 1000; Error: 0.46735; Time: 1591639613.31
Step 467 of 1000; Error: 0.46720; Time: 1591639621.97
Step 468 of 1000; Error: 0.46705; Time: 1591639630.55
Step 469 of 1000; Error: 0.46690; Time: 1591639639.11
Step 470 of 1000; Error: 0.46675; Time: 1591639647.65
Step 471 of 1000; Error: 0.46660; Time: 1591639656.31
Step 472 of 1000; Error: 0.46645; Time: 1591639665.02
Step 473 of 1000; Error: 0.46630; Time: 1591639673.64
Step 474 of 1000; Error: 0.46615; Time: 1591639682.24
Step 475 of 1000; Error: 0.46600; Time: 1591639690.83
Step 476 of 1000; Error: 0.46586; Time: 1591639699.32
Step 477 of 1000; Error: 0.46571; Time: 1591639707.93
Step 478 of 1000; Error: 0.46556; Time: 1591639716.46
Step 479 of 1000; Error: 0.46541; Time: 1591639725.20
Step 480 of 1000; Error: 0.46527; Time: 1591639733.80
Step 481 of 1000; Error: 0.46512; Time: 1591639742.36
Step 482 of 1000; Error: 0.46498; Time: 1591639750.89
Step 483 of 1000; Error: 0.46483; Time: 1591639759.58
Step 484 of 1000; Error: 0.46468; Time: 1591639768.10
Step 485 of 1000; Error: 0.46454; Time: 1591639776.67
Step 486 of 1000; Error: 0.46439; Time: 1591639785.24
Step 487 of 1000; Error: 0.46425; Time: 1591639794.06
Step 488 of 1000; Error: 0.46411; Time: 1591639802.74
Step 489 of 1000; Error: 0.46396; Time: 1591639811.12
Step 490 of 1000; Error: 0.46382; Time: 1591639819.66
Step 491 of 1000; Error: 0.46368; Time: 1591639828.20
Step 492 of 1000; Error: 0.46353; Time: 1591639836.78
Step 493 of 1000; Error: 0.46339; Time: 1591639845.45
Step 494 of 1000; Error: 0.46325; Time: 1591639854.14
Step 495 of 1000; Error: 0.46311; Time: 1591639863.01
Step 496 of 1000; Error: 0.46297; Time: 1591639871.58
Step 497 of 1000; Error: 0.46283; Time: 1591639880.29
Step 498 of 1000; Error: 0.46269; Time: 1591639888.95
Step 499 of 1000; Error: 0.46254; Time: 1591639897.68
Step 500 of 1000; Error: 0.46240; Time: 1591639906.22
Step 501 of 1000; Error: 0.46227; Time: 1591639914.89
Step 502 of 1000; Error: 0.46213; Time: 1591639923.73
Step 503 of 1000; Error: 0.46199; Time: 1591639932.37
Step 504 of 1000; Error: 0.46185; Time: 1591639940.84
Step 505 of 1000; Error: 0.46171; Time: 1591639949.39
Step 506 of 1000; Error: 0.46157; Time: 1591639957.98
Step 507 of 1000; Error: 0.46143; Time: 1591639966.49
Step 508 of 1000; Error: 0.46130; Time: 1591639975.14
Step 509 of 1000; Error: 0.46116; Time: 1591639983.75
Step 510 of 1000; Error: 0.46102; Time: 1591639992.96
Step 511 of 1000; Error: 0.46089; Time: 1591640001.56
Step 512 of 1000; Error: 0.46075; Time: 1591640010.00
Step 513 of 1000; Error: 0.46062; Time: 1591640018.69
Step 514 of 1000; Error: 0.46048; Time: 1591640027.33
Step 515 of 1000; Error: 0.46034; Time: 1591640036.05
Step 516 of 1000; Error: 0.46021; Time: 1591640044.62
Step 517 of 1000; Error: 0.46008; Time: 1591640053.42
Step 518 of 1000; Error: 0.45994; Time: 1591640061.98
Step 519 of 1000; Error: 0.45981; Time: 1591640070.51
Step 520 of 1000; Error: 0.45967; Time: 1591640079.11
Step 521 of 1000; Error: 0.45954; Time: 1591640087.63
Step 522 of 1000; Error: 0.45941; Time: 1591640096.15
Step 523 of 1000; Error: 0.45928; Time: 1591640104.89
Step 524 of 1000; Error: 0.45914; Time: 1591640113.41
Step 525 of 1000; Error: 0.45901; Time: 1591640122.20
Step 526 of 1000; Error: 0.45888; Time: 1591640130.76
Step 527 of 1000; Error: 0.45875; Time: 1591640139.33
Step 528 of 1000; Error: 0.45862; Time: 1591640147.77
Step 529 of 1000; Error: 0.45849; Time: 1591640156.35
Step 530 of 1000; Error: 0.45836; Time: 1591640164.89
Step 531 of 1000; Error: 0.45823; Time: 1591640173.24
Step 532 of 1000; Error: 0.45810; Time: 1591640181.73
Step 533 of 1000; Error: 0.45797; Time: 1591640190.48
Step 534 of 1000; Error: 0.45784; Time: 1591640199.11
Step 535 of 1000; Error: 0.45771; Time: 1591640207.64
Step 536 of 1000; Error: 0.45758; Time: 1591640216.20
Step 537 of 1000; Error: 0.45745; Time: 1591640224.66
Step 538 of 1000; Error: 0.45732; Time: 1591640233.26
Step 539 of 1000; Error: 0.45720; Time: 1591640241.82
Step 540 of 1000; Error: 0.45707; Time: 1591640250.43
Step 541 of 1000; Error: 0.45694; Time: 1591640259.15
Step 542 of 1000; Error: 0.45682; Time: 1591640267.67
Step 543 of 1000; Error: 0.45669; Time: 1591640276.22
Step 544 of 1000; Error: 0.45656; Time: 1591640284.72
Step 545 of 1000; Error: 0.45644; Time: 1591640293.07
Step 546 of 1000; Error: 0.45631; Time: 1591640301.77
Step 547 of 1000; Error: 0.45619; Time: 1591640310.36
Step 548 of 1000; Error: 0.45606; Time: 1591640319.18
Step 549 of 1000; Error: 0.45594; Time: 1591640327.85
Step 550 of 1000; Error: 0.45581; Time: 1591640336.49
Step 551 of 1000; Error: 0.45569; Time: 1591640345.09
Step 552 of 1000; Error: 0.45556; Time: 1591640353.71
Step 553 of 1000; Error: 0.45544; Time: 1591640362.33
Step 554 of 1000; Error: 0.45532; Time: 1591640370.92
Step 555 of 1000; Error: 0.45519; Time: 1591640379.50
Step 556 of 1000; Error: 0.45507; Time: 1591640388.38
Step 557 of 1000; Error: 0.45495; Time: 1591640396.93
Step 558 of 1000; Error: 0.45483; Time: 1591640405.55
Step 559 of 1000; Error: 0.45470; Time: 1591640413.97
Step 560 of 1000; Error: 0.45458; Time: 1591640422.57
Step 561 of 1000; Error: 0.45446; Time: 1591640431.25
Step 562 of 1000; Error: 0.45434; Time: 1591640439.94
Step 563 of 1000; Error: 0.45422; Time: 1591640448.69
Step 564 of 1000; Error: 0.45410; Time: 1591640457.49
Step 565 of 1000; Error: 0.45398; Time: 1591640466.07
Step 566 of 1000; Error: 0.45386; Time: 1591640474.71
Step 567 of 1000; Error: 0.45374; Time: 1591640483.33
Step 568 of 1000; Error: 0.45362; Time: 1591640491.91
Step 569 of 1000; Error: 0.45350; Time: 1591640500.54
Step 570 of 1000; Error: 0.45338; Time: 1591640509.12
Step 571 of 1000; Error: 0.45326; Time: 1591640518.11
Step 572 of 1000; Error: 0.45315; Time: 1591640526.84
Step 573 of 1000; Error: 0.45303; Time: 1591640535.38
Step 574 of 1000; Error: 0.45291; Time: 1591640543.80
Step 575 of 1000; Error: 0.45279; Time: 1591640552.24
Step 576 of 1000; Error: 0.45268; Time: 1591640560.55
Step 577 of 1000; Error: 0.45256; Time: 1591640568.88
Step 578 of 1000; Error: 0.45244; Time: 1591640577.45
Step 579 of 1000; Error: 0.45233; Time: 1591640586.37
Step 580 of 1000; Error: 0.45221; Time: 1591640595.04
Step 581 of 1000; Error: 0.45209; Time: 1591640603.69
Step 582 of 1000; Error: 0.45198; Time: 1591640612.30
Step 583 of 1000; Error: 0.45186; Time: 1591640620.92
Step 584 of 1000; Error: 0.45175; Time: 1591640629.51
Step 585 of 1000; Error: 0.45163; Time: 1591640638.20
Step 586 of 1000; Error: 0.45152; Time: 1591640647.02
Step 587 of 1000; Error: 0.45140; Time: 1591640655.47
Step 588 of 1000; Error: 0.45129; Time: 1591640663.91
Step 589 of 1000; Error: 0.45118; Time: 1591640672.29
Step 590 of 1000; Error: 0.45106; Time: 1591640680.91
Step 591 of 1000; Error: 0.45095; Time: 1591640689.40
Step 592 of 1000; Error: 0.45084; Time: 1591640697.92
Step 593 of 1000; Error: 0.45072; Time: 1591640706.54
Step 594 of 1000; Error: 0.45061; Time: 1591640715.44
Step 595 of 1000; Error: 0.45050; Time: 1591640724.06
Step 596 of 1000; Error: 0.45039; Time: 1591640733.06
Step 597 of 1000; Error: 0.45028; Time: 1591640741.61
Step 598 of 1000; Error: 0.45017; Time: 1591640750.19
Step 599 of 1000; Error: 0.45005; Time: 1591640758.80
Step 600 of 1000; Error: 0.44994; Time: 1591640767.42
Step 601 of 1000; Error: 0.44983; Time: 1591640775.85
Step 602 of 1000; Error: 0.44972; Time: 1591640784.62
Step 603 of 1000; Error: 0.44961; Time: 1591640793.10
Step 604 of 1000; Error: 0.44950; Time: 1591640801.61
Step 605 of 1000; Error: 0.44939; Time: 1591640810.14
Step 606 of 1000; Error: 0.44928; Time: 1591640819.91
Step 607 of 1000; Error: 0.44917; Time: 1591640828.39
Step 608 of 1000; Error: 0.44907; Time: 1591640836.95
Step 609 of 1000; Error: 0.44896; Time: 1591640845.77
Step 610 of 1000; Error: 0.44885; Time: 1591640854.55
Step 611 of 1000; Error: 0.44874; Time: 1591640863.11
Step 612 of 1000; Error: 0.44863; Time: 1591640871.81
Step 613 of 1000; Error: 0.44852; Time: 1591640880.55
Step 614 of 1000; Error: 0.44842; Time: 1591640889.16
Step 615 of 1000; Error: 0.44831; Time: 1591640897.46
Step 616 of 1000; Error: 0.44820; Time: 1591640905.90
Step 617 of 1000; Error: 0.44810; Time: 1591640914.71
Step 618 of 1000; Error: 0.44799; Time: 1591640923.31
Step 619 of 1000; Error: 0.44788; Time: 1591640931.92
Step 620 of 1000; Error: 0.44778; Time: 1591640940.47
Step 621 of 1000; Error: 0.44767; Time: 1591640949.21
Step 622 of 1000; Error: 0.44757; Time: 1591640957.92
Step 623 of 1000; Error: 0.44746; Time: 1591640966.52
Step 624 of 1000; Error: 0.44736; Time: 1591640975.21
Step 625 of 1000; Error: 0.44725; Time: 1591640984.13
Step 626 of 1000; Error: 0.44715; Time: 1591640992.86
Step 627 of 1000; Error: 0.44704; Time: 1591641001.54
Step 628 of 1000; Error: 0.44694; Time: 1591641010.18
Step 629 of 1000; Error: 0.44683; Time: 1591641018.84
Step 630 of 1000; Error: 0.44673; Time: 1591641027.47
Step 631 of 1000; Error: 0.44663; Time: 1591641036.01
Step 632 of 1000; Error: 0.44652; Time: 1591641044.86
Step 633 of 1000; Error: 0.44642; Time: 1591641053.50
Step 634 of 1000; Error: 0.44632; Time: 1591641062.16
Step 635 of 1000; Error: 0.44622; Time: 1591641070.79
Step 636 of 1000; Error: 0.44611; Time: 1591641079.56
Step 637 of 1000; Error: 0.44601; Time: 1591641088.21
Step 638 of 1000; Error: 0.44591; Time: 1591641097.05
Step 639 of 1000; Error: 0.44581; Time: 1591641105.74
Step 640 of 1000; Error: 0.44571; Time: 1591641114.70
Step 641 of 1000; Error: 0.44561; Time: 1591641123.26
Step 642 of 1000; Error: 0.44551; Time: 1591641131.64
Step 643 of 1000; Error: 0.44541; Time: 1591641140.03
Step 644 of 1000; Error: 0.44530; Time: 1591641148.60
Step 645 of 1000; Error: 0.44520; Time: 1591641157.22
Step 646 of 1000; Error: 0.44510; Time: 1591641165.86
Step 647 of 1000; Error: 0.44500; Time: 1591641174.64
Step 648 of 1000; Error: 0.44491; Time: 1591641183.33
Step 649 of 1000; Error: 0.44481; Time: 1591641191.92
Step 650 of 1000; Error: 0.44471; Time: 1591641200.52
Step 651 of 1000; Error: 0.44461; Time: 1591641209.12
Step 652 of 1000; Error: 0.44451; Time: 1591641217.66
Step 653 of 1000; Error: 0.44441; Time: 1591641226.29
Step 654 of 1000; Error: 0.44431; Time: 1591641234.78
Step 655 of 1000; Error: 0.44422; Time: 1591641243.53
Step 656 of 1000; Error: 0.44412; Time: 1591641252.05
Step 657 of 1000; Error: 0.44402; Time: 1591641260.51
Step 658 of 1000; Error: 0.44392; Time: 1591641268.83
Step 659 of 1000; Error: 0.44383; Time: 1591641277.40
Step 660 of 1000; Error: 0.44373; Time: 1591641286.02
Step 661 of 1000; Error: 0.44363; Time: 1591641294.57
Step 662 of 1000; Error: 0.44354; Time: 1591641303.15
Step 663 of 1000; Error: 0.44344; Time: 1591641312.12
Step 664 of 1000; Error: 0.44334; Time: 1591641320.92
Step 665 of 1000; Error: 0.44325; Time: 1591641329.53
Step 666 of 1000; Error: 0.44315; Time: 1591641338.20
Step 667 of 1000; Error: 0.44306; Time: 1591641346.77
Step 668 of 1000; Error: 0.44296; Time: 1591641355.67
Step 669 of 1000; Error: 0.44287; Time: 1591641364.35
Step 670 of 1000; Error: 0.44277; Time: 1591641373.15
Step 671 of 1000; Error: 0.44268; Time: 1591641381.88
Step 672 of 1000; Error: 0.44258; Time: 1591641390.46
Step 673 of 1000; Error: 0.44249; Time: 1591641399.24
Step 674 of 1000; Error: 0.44239; Time: 1591641407.84
Step 675 of 1000; Error: 0.44230; Time: 1591641416.50
Step 676 of 1000; Error: 0.44221; Time: 1591641425.19
Step 677 of 1000; Error: 0.44211; Time: 1591641433.88
Step 678 of 1000; Error: 0.44202; Time: 1591641442.87
Step 679 of 1000; Error: 0.44193; Time: 1591641451.48
Step 680 of 1000; Error: 0.44184; Time: 1591641460.06
Step 681 of 1000; Error: 0.44174; Time: 1591641468.69
Step 682 of 1000; Error: 0.44165; Time: 1591641477.33
Step 683 of 1000; Error: 0.44156; Time: 1591641485.91
Step 684 of 1000; Error: 0.44147; Time: 1591641494.43
Step 685 of 1000; Error: 0.44138; Time: 1591641502.98
Step 686 of 1000; Error: 0.44128; Time: 1591641511.50
Step 687 of 1000; Error: 0.44119; Time: 1591641519.84
Step 688 of 1000; Error: 0.44110; Time: 1591641528.32
Step 689 of 1000; Error: 0.44101; Time: 1591641536.83
Step 690 of 1000; Error: 0.44092; Time: 1591641545.45
Step 691 of 1000; Error: 0.44083; Time: 1591641553.97
Step 692 of 1000; Error: 0.44074; Time: 1591641562.44
Step 693 of 1000; Error: 0.44065; Time: 1591641571.13
Step 694 of 1000; Error: 0.44056; Time: 1591641579.74
Step 695 of 1000; Error: 0.44047; Time: 1591641588.26
Step 696 of 1000; Error: 0.44038; Time: 1591641596.73
Step 697 of 1000; Error: 0.44029; Time: 1591641605.23
Step 698 of 1000; Error: 0.44020; Time: 1591641613.61
Step 699 of 1000; Error: 0.44011; Time: 1591641621.90
Step 700 of 1000; Error: 0.44003; Time: 1591641630.31
Step 701 of 1000; Error: 0.43994; Time: 1591641639.13
Step 702 of 1000; Error: 0.43985; Time: 1591641647.63
Step 703 of 1000; Error: 0.43976; Time: 1591641656.05
Step 704 of 1000; Error: 0.43967; Time: 1591641664.54
Step 705 of 1000; Error: 0.43959; Time: 1591641673.05
Step 706 of 1000; Error: 0.43950; Time: 1591641681.52
Step 707 of 1000; Error: 0.43941; Time: 1591641690.04
Step 708 of 1000; Error: 0.43932; Time: 1591641698.55
Step 709 of 1000; Error: 0.43924; Time: 1591641707.22
Step 710 of 1000; Error: 0.43915; Time: 1591641715.74
Step 711 of 1000; Error: 0.43906; Time: 1591641724.27
Step 712 of 1000; Error: 0.43898; Time: 1591641732.63
Step 713 of 1000; Error: 0.43889; Time: 1591641741.25
Step 714 of 1000; Error: 0.43880; Time: 1591641749.97
Step 715 of 1000; Error: 0.43872; Time: 1591641758.65
Step 716 of 1000; Error: 0.43863; Time: 1591641767.43
Step 717 of 1000; Error: 0.43855; Time: 1591641776.01
Step 718 of 1000; Error: 0.43846; Time: 1591641784.60
Step 719 of 1000; Error: 0.43838; Time: 1591641793.17
Step 720 of 1000; Error: 0.43829; Time: 1591641801.84
Step 721 of 1000; Error: 0.43821; Time: 1591641810.42
Step 722 of 1000; Error: 0.43812; Time: 1591641819.02
Step 723 of 1000; Error: 0.43804; Time: 1591641827.62
Step 724 of 1000; Error: 0.43796; Time: 1591641836.41
Step 725 of 1000; Error: 0.43787; Time: 1591641845.10
Step 726 of 1000; Error: 0.43779; Time: 1591641853.44
Step 727 of 1000; Error: 0.43771; Time: 1591641861.90
Step 728 of 1000; Error: 0.43762; Time: 1591641870.32
Step 729 of 1000; Error: 0.43754; Time: 1591641878.90
Step 730 of 1000; Error: 0.43746; Time: 1591641887.54
Step 731 of 1000; Error: 0.43737; Time: 1591641896.11
Step 732 of 1000; Error: 0.43729; Time: 1591641904.91
Step 733 of 1000; Error: 0.43721; Time: 1591641913.42
Step 734 of 1000; Error: 0.43713; Time: 1591641921.95
Step 735 of 1000; Error: 0.43704; Time: 1591641930.60
Step 736 of 1000; Error: 0.43696; Time: 1591641939.16
Step 737 of 1000; Error: 0.43688; Time: 1591641947.77
Step 738 of 1000; Error: 0.43680; Time: 1591641956.34
Step 739 of 1000; Error: 0.43672; Time: 1591641965.04
Step 740 of 1000; Error: 0.43664; Time: 1591641973.57
Step 741 of 1000; Error: 0.43656; Time: 1591641982.03
Step 742 of 1000; Error: 0.43648; Time: 1591641990.72
Step 743 of 1000; Error: 0.43639; Time: 1591641999.33
Step 744 of 1000; Error: 0.43631; Time: 1591642007.89
Step 745 of 1000; Error: 0.43623; Time: 1591642016.52
Step 746 of 1000; Error: 0.43615; Time: 1591642025.07
Step 747 of 1000; Error: 0.43607; Time: 1591642033.87
Step 748 of 1000; Error: 0.43599; Time: 1591642042.41
Step 749 of 1000; Error: 0.43592; Time: 1591642050.99
Step 750 of 1000; Error: 0.43584; Time: 1591642059.67
Step 751 of 1000; Error: 0.43576; Time: 1591642068.33
Step 752 of 1000; Error: 0.43568; Time: 1591642076.83
Step 753 of 1000; Error: 0.43560; Time: 1591642085.51
Step 754 of 1000; Error: 0.43552; Time: 1591642094.03
Step 755 of 1000; Error: 0.43544; Time: 1591642102.94
Step 756 of 1000; Error: 0.43536; Time: 1591642111.49
Step 757 of 1000; Error: 0.43529; Time: 1591642120.10
Step 758 of 1000; Error: 0.43521; Time: 1591642128.58
Step 759 of 1000; Error: 0.43513; Time: 1591642137.20
Step 760 of 1000; Error: 0.43505; Time: 1591642145.75
Step 761 of 1000; Error: 0.43498; Time: 1591642154.25
Step 762 of 1000; Error: 0.43490; Time: 1591642162.96
Step 763 of 1000; Error: 0.43482; Time: 1591642171.55
Step 764 of 1000; Error: 0.43474; Time: 1591642179.99
Step 765 of 1000; Error: 0.43467; Time: 1591642188.50
Step 766 of 1000; Error: 0.43459; Time: 1591642197.07
Step 767 of 1000; Error: 0.43451; Time: 1591642205.65
Step 768 of 1000; Error: 0.43444; Time: 1591642214.19
Step 769 of 1000; Error: 0.43436; Time: 1591642222.72
Step 770 of 1000; Error: 0.43429; Time: 1591642231.61
Step 771 of 1000; Error: 0.43421; Time: 1591642240.22
Step 772 of 1000; Error: 0.43414; Time: 1591642248.81
Step 773 of 1000; Error: 0.43406; Time: 1591642257.35
Step 774 of 1000; Error: 0.43398; Time: 1591642265.99
Step 775 of 1000; Error: 0.43391; Time: 1591642274.54
Step 776 of 1000; Error: 0.43383; Time: 1591642283.14
Step 777 of 1000; Error: 0.43376; Time: 1591642291.73
Step 778 of 1000; Error: 0.43369; Time: 1591642300.57
Step 779 of 1000; Error: 0.43361; Time: 1591642309.15
Step 780 of 1000; Error: 0.43354; Time: 1591642317.69
Step 781 of 1000; Error: 0.43346; Time: 1591642326.34
Step 782 of 1000; Error: 0.43339; Time: 1591642334.86
Step 783 of 1000; Error: 0.43332; Time: 1591642343.42
Step 784 of 1000; Error: 0.43324; Time: 1591642352.00
Step 785 of 1000; Error: 0.43317; Time: 1591642360.81
Step 786 of 1000; Error: 0.43310; Time: 1591642369.43
Step 787 of 1000; Error: 0.43302; Time: 1591642378.00
Step 788 of 1000; Error: 0.43295; Time: 1591642386.60
Step 789 of 1000; Error: 0.43288; Time: 1591642395.16
Step 790 of 1000; Error: 0.43280; Time: 1591642403.75
Step 791 of 1000; Error: 0.43273; Time: 1591642412.28
Step 792 of 1000; Error: 0.43266; Time: 1591642420.88
Step 793 of 1000; Error: 0.43259; Time: 1591642429.70
Step 794 of 1000; Error: 0.43252; Time: 1591642438.34
Step 795 of 1000; Error: 0.43244; Time: 1591642446.93
Step 796 of 1000; Error: 0.43237; Time: 1591642455.47
Step 797 of 1000; Error: 0.43230; Time: 1591642463.79
Step 798 of 1000; Error: 0.43223; Time: 1591642472.20
Step 799 of 1000; Error: 0.43216; Time: 1591642480.77
Step 800 of 1000; Error: 0.43209; Time: 1591642489.45
Step 801 of 1000; Error: 0.43202; Time: 1591642498.30
Step 802 of 1000; Error: 0.43195; Time: 1591642506.91
Step 803 of 1000; Error: 0.43188; Time: 1591642515.41
Step 804 of 1000; Error: 0.43181; Time: 1591642523.96
Step 805 of 1000; Error: 0.43174; Time: 1591642532.57
Step 806 of 1000; Error: 0.43167; Time: 1591642541.16
Step 807 of 1000; Error: 0.43160; Time: 1591642549.80
Step 808 of 1000; Error: 0.43153; Time: 1591642558.53
Step 809 of 1000; Error: 0.43146; Time: 1591642567.07
Step 810 of 1000; Error: 0.43139; Time: 1591642575.56
Step 811 of 1000; Error: 0.43132; Time: 1591642584.11
Step 812 of 1000; Error: 0.43125; Time: 1591642592.57
Step 813 of 1000; Error: 0.43118; Time: 1591642601.17
Step 814 of 1000; Error: 0.43111; Time: 1591642609.71
Step 815 of 1000; Error: 0.43104; Time: 1591642618.20
Step 816 of 1000; Error: 0.43097; Time: 1591642626.92
Step 817 of 1000; Error: 0.43091; Time: 1591642635.49
Step 818 of 1000; Error: 0.43084; Time: 1591642644.09
Step 819 of 1000; Error: 0.43077; Time: 1591642652.69
Step 820 of 1000; Error: 0.43070; Time: 1591642661.21
Step 821 of 1000; Error: 0.43063; Time: 1591642669.70
Step 822 of 1000; Error: 0.43057; Time: 1591642678.27
Step 823 of 1000; Error: 0.43050; Time: 1591642687.25
Step 824 of 1000; Error: 0.43043; Time: 1591642695.96
Step 825 of 1000; Error: 0.43037; Time: 1591642704.50
Step 826 of 1000; Error: 0.43030; Time: 1591642713.04
Step 827 of 1000; Error: 0.43023; Time: 1591642721.52
Step 828 of 1000; Error: 0.43016; Time: 1591642730.15
Step 829 of 1000; Error: 0.43010; Time: 1591642738.60
Step 830 of 1000; Error: 0.43003; Time: 1591642747.12
Step 831 of 1000; Error: 0.42997; Time: 1591642755.77
Step 832 of 1000; Error: 0.42990; Time: 1591642764.29
Step 833 of 1000; Error: 0.42983; Time: 1591642773.01
Step 834 of 1000; Error: 0.42977; Time: 1591642781.63
Step 835 of 1000; Error: 0.42970; Time: 1591642790.26
Step 836 of 1000; Error: 0.42964; Time: 1591642798.89
Step 837 of 1000; Error: 0.42957; Time: 1591642807.51
Step 838 of 1000; Error: 0.42951; Time: 1591642817.56
Step 839 of 1000; Error: 0.42944; Time: 1591642826.32
Step 840 of 1000; Error: 0.42938; Time: 1591642835.01
Step 841 of 1000; Error: 0.42931; Time: 1591642843.66
Step 842 of 1000; Error: 0.42925; Time: 1591642852.24
Step 843 of 1000; Error: 0.42918; Time: 1591642860.80
Step 844 of 1000; Error: 0.42912; Time: 1591642869.70
Step 845 of 1000; Error: 0.42905; Time: 1591642878.75
Step 846 of 1000; Error: 0.42899; Time: 1591642888.61
Step 847 of 1000; Error: 0.42893; Time: 1591642897.42
Step 848 of 1000; Error: 0.42886; Time: 1591642906.17
Step 849 of 1000; Error: 0.42880; Time: 1591642914.68
Step 850 of 1000; Error: 0.42874; Time: 1591642923.21
Step 851 of 1000; Error: 0.42867; Time: 1591642931.84
Step 852 of 1000; Error: 0.42861; Time: 1591642940.44
Step 853 of 1000; Error: 0.42855; Time: 1591642949.23
Step 854 of 1000; Error: 0.42848; Time: 1591642958.02
Step 855 of 1000; Error: 0.42842; Time: 1591642966.78
Step 856 of 1000; Error: 0.42836; Time: 1591642976.61
Step 857 of 1000; Error: 0.42830; Time: 1591642985.55
Step 858 of 1000; Error: 0.42823; Time: 1591642995.08
Step 859 of 1000; Error: 0.42817; Time: 1591643003.82
Step 860 of 1000; Error: 0.42811; Time: 1591643013.56
Step 861 of 1000; Error: 0.42805; Time: 1591643022.44
Step 862 of 1000; Error: 0.42799; Time: 1591643030.90
Step 863 of 1000; Error: 0.42792; Time: 1591643039.36
Step 864 of 1000; Error: 0.42786; Time: 1591643047.96
Step 865 of 1000; Error: 0.42780; Time: 1591643056.57
Step 866 of 1000; Error: 0.42774; Time: 1591643065.82
Step 867 of 1000; Error: 0.42768; Time: 1591643076.51
Step 868 of 1000; Error: 0.42762; Time: 1591643085.20
Step 869 of 1000; Error: 0.42756; Time: 1591643094.20
Step 870 of 1000; Error: 0.42750; Time: 1591643102.79
Step 871 of 1000; Error: 0.42744; Time: 1591643111.44
Step 872 of 1000; Error: 0.42738; Time: 1591643120.11
Step 873 of 1000; Error: 0.42732; Time: 1591643128.79
Step 874 of 1000; Error: 0.42726; Time: 1591643137.49
Step 875 of 1000; Error: 0.42720; Time: 1591643146.22
Step 876 of 1000; Error: 0.42714; Time: 1591643155.16
Step 877 of 1000; Error: 0.42708; Time: 1591643163.81
Step 878 of 1000; Error: 0.42702; Time: 1591643172.36
Step 879 of 1000; Error: 0.42696; Time: 1591643180.96
Step 880 of 1000; Error: 0.42690; Time: 1591643189.50
Step 881 of 1000; Error: 0.42684; Time: 1591643198.00
Step 882 of 1000; Error: 0.42678; Time: 1591643206.63
Step 883 of 1000; Error: 0.42672; Time: 1591643215.28
Step 884 of 1000; Error: 0.42666; Time: 1591643224.09
Step 885 of 1000; Error: 0.42660; Time: 1591643232.65
Step 886 of 1000; Error: 0.42654; Time: 1591643241.26
Step 887 of 1000; Error: 0.42649; Time: 1591643249.78
Step 888 of 1000; Error: 0.42643; Time: 1591643258.31
Step 889 of 1000; Error: 0.42637; Time: 1591643266.83
Step 890 of 1000; Error: 0.42631; Time: 1591643275.39
Step 891 of 1000; Error: 0.42625; Time: 1591643284.15
Step 892 of 1000; Error: 0.42620; Time: 1591643292.54
Step 893 of 1000; Error: 0.42614; Time: 1591643300.96
Step 894 of 1000; Error: 0.42608; Time: 1591643309.37
Step 895 of 1000; Error: 0.42602; Time: 1591643317.85
Step 896 of 1000; Error: 0.42597; Time: 1591643326.34
Step 897 of 1000; Error: 0.42591; Time: 1591643334.93
Step 898 of 1000; Error: 0.42585; Time: 1591643343.27
Step 899 of 1000; Error: 0.42579; Time: 1591643351.93
Step 900 of 1000; Error: 0.42574; Time: 1591643360.55
Step 901 of 1000; Error: 0.42568; Time: 1591643369.41
Step 902 of 1000; Error: 0.42562; Time: 1591643377.92
Step 903 of 1000; Error: 0.42557; Time: 1591643386.49
Step 904 of 1000; Error: 0.42551; Time: 1591643395.18
Step 905 of 1000; Error: 0.42546; Time: 1591643403.77
Step 906 of 1000; Error: 0.42540; Time: 1591643412.43
Step 907 of 1000; Error: 0.42534; Time: 1591643421.14
Step 908 of 1000; Error: 0.42529; Time: 1591643429.97
Step 909 of 1000; Error: 0.42523; Time: 1591643438.63
Step 910 of 1000; Error: 0.42518; Time: 1591643447.68
Step 911 of 1000; Error: 0.42512; Time: 1591643457.03
Step 912 of 1000; Error: 0.42507; Time: 1591643468.71
Step 913 of 1000; Error: 0.42501; Time: 1591643479.35
Step 914 of 1000; Error: 0.42496; Time: 1591643490.14
Step 915 of 1000; Error: 0.42490; Time: 1591643501.08
Step 916 of 1000; Error: 0.42485; Time: 1591643511.18
Step 917 of 1000; Error: 0.42479; Time: 1591643521.09
Step 918 of 1000; Error: 0.42474; Time: 1591643530.97
Step 919 of 1000; Error: 0.42468; Time: 1591643540.76
Step 920 of 1000; Error: 0.42463; Time: 1591643550.88
Step 921 of 1000; Error: 0.42457; Time: 1591643560.64
Step 922 of 1000; Error: 0.42452; Time: 1591643570.28
Step 923 of 1000; Error: 0.42447; Time: 1591643580.00
Step 924 of 1000; Error: 0.42441; Time: 1591643589.81
Step 925 of 1000; Error: 0.42436; Time: 1591643599.41
Step 926 of 1000; Error: 0.42431; Time: 1591643609.08
Step 927 of 1000; Error: 0.42425; Time: 1591643618.88
Step 928 of 1000; Error: 0.42420; Time: 1591643628.51
Step 929 of 1000; Error: 0.42414; Time: 1591643638.18
Step 930 of 1000; Error: 0.42409; Time: 1591643647.83
Step 931 of 1000; Error: 0.42404; Time: 1591643657.51
Step 932 of 1000; Error: 0.42399; Time: 1591643667.14
Step 933 of 1000; Error: 0.42393; Time: 1591643676.94
Step 934 of 1000; Error: 0.42388; Time: 1591643686.66
Step 935 of 1000; Error: 0.42383; Time: 1591643696.14
Step 936 of 1000; Error: 0.42378; Time: 1591643705.68
Step 937 of 1000; Error: 0.42372; Time: 1591643715.27
Step 938 of 1000; Error: 0.42367; Time: 1591643724.85
Step 939 of 1000; Error: 0.42362; Time: 1591643734.49
Step 940 of 1000; Error: 0.42357; Time: 1591643744.21
Step 941 of 1000; Error: 0.42351; Time: 1591643753.14
Step 942 of 1000; Error: 0.42346; Time: 1591643761.70
Step 943 of 1000; Error: 0.42341; Time: 1591643770.48
Step 944 of 1000; Error: 0.42336; Time: 1591643779.33
Step 945 of 1000; Error: 0.42331; Time: 1591643788.10
Step 946 of 1000; Error: 0.42326; Time: 1591643796.69
Step 947 of 1000; Error: 0.42321; Time: 1591643805.56
Step 948 of 1000; Error: 0.42315; Time: 1591643814.72
Step 949 of 1000; Error: 0.42310; Time: 1591643823.47
Step 950 of 1000; Error: 0.42305; Time: 1591643832.25
Step 951 of 1000; Error: 0.42300; Time: 1591643841.37
Step 952 of 1000; Error: 0.42295; Time: 1591643850.30
Step 953 of 1000; Error: 0.42290; Time: 1591643859.39
Step 954 of 1000; Error: 0.42285; Time: 1591643868.66
Step 955 of 1000; Error: 0.42280; Time: 1591643877.77
Step 956 of 1000; Error: 0.42275; Time: 1591643886.53
Step 957 of 1000; Error: 0.42270; Time: 1591643895.10
Step 958 of 1000; Error: 0.42265; Time: 1591643905.80
Step 959 of 1000; Error: 0.42260; Time: 1591643914.37
Step 960 of 1000; Error: 0.42255; Time: 1591643923.19
Step 961 of 1000; Error: 0.42250; Time: 1591643933.56
Step 962 of 1000; Error: 0.42245; Time: 1591643942.42
Step 963 of 1000; Error: 0.42240; Time: 1591643950.91
Step 964 of 1000; Error: 0.42235; Time: 1591643960.31
Step 965 of 1000; Error: 0.42230; Time: 1591643970.50
Step 966 of 1000; Error: 0.42225; Time: 1591643979.33
Step 967 of 1000; Error: 0.42220; Time: 1591643989.65
Step 968 of 1000; Error: 0.42215; Time: 1591644001.39
Step 969 of 1000; Error: 0.42211; Time: 1591644012.31
Step 970 of 1000; Error: 0.42206; Time: 1591644024.48
Step 971 of 1000; Error: 0.42201; Time: 1591644035.28
Step 972 of 1000; Error: 0.42196; Time: 1591644045.36
Step 973 of 1000; Error: 0.42191; Time: 1591644057.28
Step 974 of 1000; Error: 0.42186; Time: 1591644067.84
Step 975 of 1000; Error: 0.42181; Time: 1591644078.46
Step 976 of 1000; Error: 0.42177; Time: 1591644088.75
Step 977 of 1000; Error: 0.42172; Time: 1591644099.01
Step 978 of 1000; Error: 0.42167; Time: 1591644109.20
Step 979 of 1000; Error: 0.42162; Time: 1591644119.39
Step 980 of 1000; Error: 0.42157; Time: 1591644129.45
Step 981 of 1000; Error: 0.42153; Time: 1591644139.85
Step 982 of 1000; Error: 0.42148; Time: 1591644150.20
Step 983 of 1000; Error: 0.42143; Time: 1591644160.45
Step 984 of 1000; Error: 0.42138; Time: 1591644171.20
Step 985 of 1000; Error: 0.42134; Time: 1591644181.46
Step 986 of 1000; Error: 0.42129; Time: 1591644191.48
Step 987 of 1000; Error: 0.42124; Time: 1591644201.68
Step 988 of 1000; Error: 0.42120; Time: 1591644212.19
Step 989 of 1000; Error: 0.42115; Time: 1591644222.38
Step 990 of 1000; Error: 0.42110; Time: 1591644232.53
Step 991 of 1000; Error: 0.42106; Time: 1591644242.75
Step 992 of 1000; Error: 0.42101; Time: 1591644252.99
Step 993 of 1000; Error: 0.42096; Time: 1591644263.22
Step 994 of 1000; Error: 0.42092; Time: 1591644272.58
Step 995 of 1000; Error: 0.42087; Time: 1591644281.19
Step 996 of 1000; Error: 0.42082; Time: 1591644289.84
Step 997 of 1000; Error: 0.42078; Time: 1591644298.38
Step 998 of 1000; Error: 0.42073; Time: 1591644306.86
Step 999 of 1000; Error: 0.42069; Time: 1591644315.74
Step 1000 of 1000; Error: 0.42064; Time: 1591644324.52
done in 8878.066s.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>
<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">matrix_factorization</span><span class="p">(</span><span class="n">ratings_data</span><span class="p">,</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">movie_feature_num</span><span class="p">,</span><span class="n">steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.0002</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;done in </span><span class="si">%0.3f</span><span class="s2">s.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Step 1 of 10; Error: 0.41710; Time: 1591644332.87
Step 2 of 10; Error: 0.41590; Time: 1591644341.53
Step 3 of 10; Error: 0.41533; Time: 1591644349.95
Step 4 of 10; Error: 0.41501; Time: 1591644358.47
Step 5 of 10; Error: 0.41481; Time: 1591644367.25
Step 6 of 10; Error: 0.41467; Time: 1591644375.91
Step 7 of 10; Error: 0.41457; Time: 1591644384.31
Step 8 of 10; Error: 0.41449; Time: 1591644392.73
Step 9 of 10; Error: 0.41443; Time: 1591644400.94
Step 10 of 10; Error: 0.41438; Time: 1591644409.57
done in 85.026s.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">optimal_movie_features</span><span class="o">=</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">optimal_user_prefs</span><span class="o">=</span><span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4>Step3. Now let&#39;s make predictions with the movie_features and user_prefs!</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">all_predictions</span> <span class="o">=</span> <span class="n">optimal_movie_features</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">optimal_user_prefs</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">all_predictions</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[20]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[ 4.57632727,  3.29874172, -0.57372615, ...,  3.42333591,
         3.58646724,  4.03163058],
       [ 4.22504574,  3.11283782,  0.67355939, ...,  3.2436625 ,
         3.02610114,  3.31005417],
       [ 4.65344092,  3.98655178,  1.98884623, ...,  3.72081556,
         3.46242836,  4.20764924],
       ...,
       [ 3.10468959,  3.4967971 ,  2.82862443, ...,  2.97781001,
         2.71591515,  3.03785131],
       [ 2.94589241,  2.51770235,  1.0274263 , ...,  2.45567164,
         2.30338111,  3.52117226],
       [ 4.32234205,  3.29173442, -0.19344854, ...,  3.00322746,
         3.33234526,  3.52786166]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">predicted_ratings_df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">all_predictions</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">movie_index</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="n">user_header</span><span class="p">)</span>
<span class="n">predicted_ratings_df</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[21]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>...</th>
      <th>601</th>
      <th>602</th>
      <th>603</th>
      <th>604</th>
      <th>605</th>
      <th>606</th>
      <th>607</th>
      <th>608</th>
      <th>609</th>
      <th>610</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>4.576327</td>
      <td>3.298742</td>
      <td>-0.573726</td>
      <td>3.065280</td>
      <td>4.041270</td>
      <td>4.509608</td>
      <td>4.229836</td>
      <td>4.008992</td>
      <td>3.531854</td>
      <td>4.177835</td>
      <td>...</td>
      <td>4.436352</td>
      <td>4.116405</td>
      <td>3.285635</td>
      <td>4.253752</td>
      <td>3.608613</td>
      <td>3.923789</td>
      <td>3.528806</td>
      <td>3.423336</td>
      <td>3.586467</td>
      <td>4.031631</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.225046</td>
      <td>3.112838</td>
      <td>0.673559</td>
      <td>2.613146</td>
      <td>2.608790</td>
      <td>3.411601</td>
      <td>2.744982</td>
      <td>3.438210</td>
      <td>3.158868</td>
      <td>3.672580</td>
      <td>...</td>
      <td>3.736633</td>
      <td>2.991953</td>
      <td>2.795275</td>
      <td>3.210839</td>
      <td>3.048465</td>
      <td>3.288001</td>
      <td>3.389825</td>
      <td>3.243662</td>
      <td>3.026101</td>
      <td>3.310054</td>
    </tr>
    <tr>
      <th>6</th>
      <td>4.653441</td>
      <td>3.986552</td>
      <td>1.988846</td>
      <td>3.462135</td>
      <td>3.382861</td>
      <td>4.028064</td>
      <td>3.826765</td>
      <td>3.320106</td>
      <td>4.254994</td>
      <td>2.120419</td>
      <td>...</td>
      <td>4.256372</td>
      <td>3.920565</td>
      <td>3.949598</td>
      <td>3.907068</td>
      <td>3.545308</td>
      <td>3.950980</td>
      <td>3.919248</td>
      <td>3.720816</td>
      <td>3.462428</td>
      <td>4.207649</td>
    </tr>
    <tr>
      <th>47</th>
      <td>4.927991</td>
      <td>3.819982</td>
      <td>1.221983</td>
      <td>4.068381</td>
      <td>4.104366</td>
      <td>3.865309</td>
      <td>3.721193</td>
      <td>4.282163</td>
      <td>4.198218</td>
      <td>1.563340</td>
      <td>...</td>
      <td>4.436353</td>
      <td>3.878701</td>
      <td>4.076148</td>
      <td>3.968787</td>
      <td>3.479808</td>
      <td>4.219721</td>
      <td>4.160298</td>
      <td>3.762983</td>
      <td>3.546329</td>
      <td>4.515509</td>
    </tr>
    <tr>
      <th>50</th>
      <td>4.945753</td>
      <td>3.865461</td>
      <td>1.215865</td>
      <td>4.017897</td>
      <td>4.229672</td>
      <td>3.969369</td>
      <td>4.019960</td>
      <td>4.120125</td>
      <td>4.483305</td>
      <td>1.254829</td>
      <td>...</td>
      <td>4.537716</td>
      <td>4.123298</td>
      <td>4.432154</td>
      <td>4.052817</td>
      <td>3.494043</td>
      <td>4.407129</td>
      <td>4.057007</td>
      <td>3.813079</td>
      <td>3.603213</td>
      <td>4.699527</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>160341</th>
      <td>2.762888</td>
      <td>0.544372</td>
      <td>-5.385754</td>
      <td>3.684406</td>
      <td>5.598865</td>
      <td>2.770244</td>
      <td>2.535429</td>
      <td>6.055276</td>
      <td>-0.038912</td>
      <td>3.063218</td>
      <td>...</td>
      <td>2.784209</td>
      <td>2.177704</td>
      <td>0.237578</td>
      <td>3.254233</td>
      <td>2.037353</td>
      <td>2.203467</td>
      <td>2.503317</td>
      <td>1.197789</td>
      <td>2.208790</td>
      <td>2.500155</td>
    </tr>
    <tr>
      <th>160527</th>
      <td>6.169331</td>
      <td>7.171250</td>
      <td>7.824729</td>
      <td>6.515697</td>
      <td>3.464823</td>
      <td>5.700220</td>
      <td>3.897971</td>
      <td>4.351633</td>
      <td>4.319437</td>
      <td>3.580575</td>
      <td>...</td>
      <td>4.954509</td>
      <td>4.158238</td>
      <td>2.714842</td>
      <td>5.670838</td>
      <td>5.826102</td>
      <td>3.527121</td>
      <td>7.502713</td>
      <td>5.124145</td>
      <td>4.587500</td>
      <td>4.570509</td>
    </tr>
    <tr>
      <th>160836</th>
      <td>3.104690</td>
      <td>3.496797</td>
      <td>2.828624</td>
      <td>0.833757</td>
      <td>1.200934</td>
      <td>3.895406</td>
      <td>4.083018</td>
      <td>-0.079608</td>
      <td>4.231100</td>
      <td>2.800576</td>
      <td>...</td>
      <td>3.275190</td>
      <td>3.871782</td>
      <td>3.761792</td>
      <td>3.129501</td>
      <td>2.963648</td>
      <td>3.044576</td>
      <td>2.066321</td>
      <td>2.977810</td>
      <td>2.715915</td>
      <td>3.037851</td>
    </tr>
    <tr>
      <th>163937</th>
      <td>2.945892</td>
      <td>2.517702</td>
      <td>1.027426</td>
      <td>2.174512</td>
      <td>2.890368</td>
      <td>2.657071</td>
      <td>3.521530</td>
      <td>1.614040</td>
      <td>3.894627</td>
      <td>-0.887109</td>
      <td>...</td>
      <td>3.024667</td>
      <td>3.383577</td>
      <td>4.160300</td>
      <td>2.644702</td>
      <td>2.065512</td>
      <td>3.344752</td>
      <td>1.965456</td>
      <td>2.455672</td>
      <td>2.303381</td>
      <td>3.521172</td>
    </tr>
    <tr>
      <th>163981</th>
      <td>4.322342</td>
      <td>3.291734</td>
      <td>-0.193449</td>
      <td>4.368915</td>
      <td>4.547686</td>
      <td>4.179617</td>
      <td>3.406296</td>
      <td>5.064547</td>
      <td>2.196775</td>
      <td>3.760197</td>
      <td>...</td>
      <td>3.920292</td>
      <td>3.303415</td>
      <td>1.742424</td>
      <td>4.293725</td>
      <td>3.648270</td>
      <td>3.066852</td>
      <td>4.324047</td>
      <td>3.003227</td>
      <td>3.332345</td>
      <td>3.527862</td>
    </tr>
  </tbody>
</table>
<p>9724 rows &#215; 610 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">user1_rating</span><span class="o">=</span><span class="n">predicted_ratings_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">user1_rating</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[22]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>26761     12.014603
83969     11.896987
51167     11.551188
144222    11.279761
35807     10.925905
            ...    
1519      -3.059624
91414     -3.366135
136850    -4.068481
82684     -4.858991
5764      -5.199694
Name: 1, Length: 9724, dtype: float64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4>Step4. Print Mean Absolute Error for each user and overall mean absolute</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#evaluate model precision, print the Mean Absolute Error</span>
<span class="k">def</span> <span class="nf">print_MAE</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">A</span><span class="p">):</span>
    <span class="n">totCount</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">totError</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">M</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
    <span class="n">N</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">R</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">err_u</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">rateCount_u</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">ratings_data</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">u</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span> <span class="c1">### Only use known ratings computing error</span>
                <span class="n">rateCount_u</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">err_u</span> <span class="o">+=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">all_predictions</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">u</span><span class="p">]</span><span class="o">-</span> <span class="n">ratings_data</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">u</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Absolute Error for User </span><span class="si">%d</span><span class="s2"> = </span><span class="si">%0.5f</span><span class="s2">&quot;</span> <span class="o">%</span><span class="p">(</span><span class="n">u</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">err_u</span><span class="o">/</span><span class="n">rateCount_u</span><span class="p">))</span>
        <span class="n">totCount</span> <span class="o">+=</span> <span class="n">rateCount_u</span>
        <span class="n">totError</span> <span class="o">+=</span> <span class="n">err_u</span>
    <span class="nb">print</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Overall Mean Absolute Error = </span><span class="si">%0.5f</span><span class="s2">&quot;</span> <span class="o">%</span><span class="p">(</span><span class="n">totError</span><span class="o">/</span><span class="n">totCount</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">print_MAE</span><span class="p">(</span><span class="n">ratings_data</span><span class="p">,</span> <span class="n">all_predictions</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Mean Absolute Error for User 1 = 0.50124
Mean Absolute Error for User 2 = 0.47996
Mean Absolute Error for User 3 = 0.18896
Mean Absolute Error for User 4 = 0.65659
Mean Absolute Error for User 5 = 0.60821
Mean Absolute Error for User 6 = 0.45149
Mean Absolute Error for User 7 = 0.65619
Mean Absolute Error for User 8 = 0.63872
Mean Absolute Error for User 9 = 0.39392
Mean Absolute Error for User 10 = 0.38640
Mean Absolute Error for User 11 = 0.47775
Mean Absolute Error for User 12 = 0.49727
Mean Absolute Error for User 13 = 0.43224
Mean Absolute Error for User 14 = 0.53480
Mean Absolute Error for User 15 = 0.59225
Mean Absolute Error for User 16 = 0.39720
Mean Absolute Error for User 17 = 0.39172
Mean Absolute Error for User 18 = 0.33318
Mean Absolute Error for User 19 = 0.53405
Mean Absolute Error for User 20 = 0.42748
Mean Absolute Error for User 21 = 0.44092
Mean Absolute Error for User 22 = 0.50396
Mean Absolute Error for User 23 = 0.42122
Mean Absolute Error for User 24 = 0.33698
Mean Absolute Error for User 25 = 0.22927
Mean Absolute Error for User 26 = 0.29383
Mean Absolute Error for User 27 = 0.45570
Mean Absolute Error for User 28 = 0.54736
Mean Absolute Error for User 29 = 0.36810
Mean Absolute Error for User 30 = 0.29704
Mean Absolute Error for User 31 = 0.51759
Mean Absolute Error for User 32 = 0.49327
Mean Absolute Error for User 33 = 0.53516
Mean Absolute Error for User 34 = 0.51750
Mean Absolute Error for User 35 = 0.55053
Mean Absolute Error for User 36 = 0.52545
Mean Absolute Error for User 37 = 0.47190
Mean Absolute Error for User 38 = 0.64042
Mean Absolute Error for User 39 = 0.61355
Mean Absolute Error for User 40 = 0.54654
Mean Absolute Error for User 41 = 0.55555
Mean Absolute Error for User 42 = 0.58059
Mean Absolute Error for User 43 = 0.47736
Mean Absolute Error for User 44 = 0.51728
Mean Absolute Error for User 45 = 0.56523
Mean Absolute Error for User 46 = 0.55584
Mean Absolute Error for User 47 = 0.50960
Mean Absolute Error for User 48 = 0.49678
Mean Absolute Error for User 49 = 0.21125
Mean Absolute Error for User 50 = 0.30341
Mean Absolute Error for User 51 = 0.47155
Mean Absolute Error for User 52 = 0.47403
Mean Absolute Error for User 53 = 0.32744
Mean Absolute Error for User 54 = 0.23803
Mean Absolute Error for User 55 = 0.30579
Mean Absolute Error for User 56 = 0.52111
Mean Absolute Error for User 57 = 0.52180
Mean Absolute Error for User 58 = 0.65963
Mean Absolute Error for User 59 = 0.51228
Mean Absolute Error for User 60 = 0.42642
Mean Absolute Error for User 61 = 0.32519
Mean Absolute Error for User 62 = 0.42405
Mean Absolute Error for User 63 = 0.62471
Mean Absolute Error for User 64 = 0.44207
Mean Absolute Error for User 65 = 0.36231
Mean Absolute Error for User 66 = 0.44111
Mean Absolute Error for User 67 = 0.42837
Mean Absolute Error for User 68 = 0.53735
Mean Absolute Error for User 69 = 0.38344
Mean Absolute Error for User 70 = 0.36088
Mean Absolute Error for User 71 = 0.40157
Mean Absolute Error for User 72 = 0.21695
Mean Absolute Error for User 73 = 0.57219
Mean Absolute Error for User 74 = 0.37541
Mean Absolute Error for User 75 = 0.73509
Mean Absolute Error for User 76 = 0.72397
Mean Absolute Error for User 77 = 0.55401
Mean Absolute Error for User 78 = 0.44658
Mean Absolute Error for User 79 = 0.46142
Mean Absolute Error for User 80 = 0.32476
Mean Absolute Error for User 81 = 0.72484
Mean Absolute Error for User 82 = 0.46782
Mean Absolute Error for User 83 = 0.56867
Mean Absolute Error for User 84 = 0.45809
Mean Absolute Error for User 85 = 0.44378
Mean Absolute Error for User 86 = 0.33622
Mean Absolute Error for User 87 = 0.24983
Mean Absolute Error for User 88 = 0.30191
Mean Absolute Error for User 89 = 0.26617
Mean Absolute Error for User 90 = 0.29076
Mean Absolute Error for User 91 = 0.51514
Mean Absolute Error for User 92 = 0.43927
Mean Absolute Error for User 93 = 0.43301
Mean Absolute Error for User 94 = 0.49739
Mean Absolute Error for User 95 = 0.42701
Mean Absolute Error for User 96 = 0.47770
Mean Absolute Error for User 97 = 0.44896
Mean Absolute Error for User 98 = 0.45848
Mean Absolute Error for User 99 = 0.55090
Mean Absolute Error for User 100 = 0.42281
Mean Absolute Error for User 101 = 0.47716
Mean Absolute Error for User 102 = 0.48972
Mean Absolute Error for User 103 = 0.46211
Mean Absolute Error for User 104 = 0.42279
Mean Absolute Error for User 105 = 0.32519
Mean Absolute Error for User 106 = 0.30675
Mean Absolute Error for User 107 = 0.43261
Mean Absolute Error for User 108 = 0.43576
Mean Absolute Error for User 109 = 0.45371
Mean Absolute Error for User 110 = 0.32308
Mean Absolute Error for User 111 = 0.53748
Mean Absolute Error for User 112 = 0.56445
Mean Absolute Error for User 113 = 0.53053
Mean Absolute Error for User 114 = 0.52612
Mean Absolute Error for User 115 = 0.57417
Mean Absolute Error for User 116 = 0.61723
Mean Absolute Error for User 117 = 0.44011
Mean Absolute Error for User 118 = 0.48486
Mean Absolute Error for User 119 = 0.35644
Mean Absolute Error for User 120 = 0.62416
Mean Absolute Error for User 121 = 0.51645
Mean Absolute Error for User 122 = 0.28224
Mean Absolute Error for User 123 = 0.30336
Mean Absolute Error for User 124 = 0.42009
Mean Absolute Error for User 125 = 0.44551
Mean Absolute Error for User 126 = 0.61028
Mean Absolute Error for User 127 = 0.40639
Mean Absolute Error for User 128 = 0.45787
Mean Absolute Error for User 129 = 0.39373
Mean Absolute Error for User 130 = 0.58222
Mean Absolute Error for User 131 = 0.42465
Mean Absolute Error for User 132 = 0.51416
Mean Absolute Error for User 133 = 0.39005
Mean Absolute Error for User 134 = 0.48842
Mean Absolute Error for User 135 = 0.63461
Mean Absolute Error for User 136 = 0.49775
Mean Absolute Error for User 137 = 0.48343
Mean Absolute Error for User 138 = 0.52616
Mean Absolute Error for User 139 = 0.55991
Mean Absolute Error for User 140 = 0.43116
Mean Absolute Error for User 141 = 0.54071
Mean Absolute Error for User 142 = 0.43804
Mean Absolute Error for User 143 = 0.45229
Mean Absolute Error for User 144 = 0.46956
Mean Absolute Error for User 145 = 0.43420
Mean Absolute Error for User 146 = 0.49543
Mean Absolute Error for User 147 = 0.35592
Mean Absolute Error for User 148 = 0.46983
Mean Absolute Error for User 149 = 0.72946
Mean Absolute Error for User 150 = 0.42562
Mean Absolute Error for User 151 = 0.44405
Mean Absolute Error for User 152 = 0.40849
Mean Absolute Error for User 153 = 0.58863
Mean Absolute Error for User 154 = 0.34255
Mean Absolute Error for User 155 = 0.43050
Mean Absolute Error for User 156 = 0.52724
Mean Absolute Error for User 157 = 0.43663
Mean Absolute Error for User 158 = 0.35707
Mean Absolute Error for User 159 = 0.50244
Mean Absolute Error for User 160 = 0.62418
Mean Absolute Error for User 161 = 0.51663
Mean Absolute Error for User 162 = 0.56842
Mean Absolute Error for User 163 = 0.44161
Mean Absolute Error for User 164 = 0.48668
Mean Absolute Error for User 165 = 0.39394
Mean Absolute Error for User 166 = 0.39269
Mean Absolute Error for User 167 = 0.64802
Mean Absolute Error for User 168 = 0.33384
Mean Absolute Error for User 169 = 0.41347
Mean Absolute Error for User 170 = 0.46440
Mean Absolute Error for User 171 = 0.47384
Mean Absolute Error for User 172 = 0.35625
Mean Absolute Error for User 173 = 0.52551
Mean Absolute Error for User 174 = 0.62718
Mean Absolute Error for User 175 = 0.09118
Mean Absolute Error for User 176 = 0.48578
Mean Absolute Error for User 177 = 0.55477
Mean Absolute Error for User 178 = 0.46136
Mean Absolute Error for User 179 = 0.39626
Mean Absolute Error for User 180 = 0.31220
Mean Absolute Error for User 181 = 0.51001
Mean Absolute Error for User 182 = 0.53933
Mean Absolute Error for User 183 = 0.41492
Mean Absolute Error for User 184 = 0.25494
Mean Absolute Error for User 185 = 0.36649
Mean Absolute Error for User 186 = 0.41796
Mean Absolute Error for User 187 = 0.47329
Mean Absolute Error for User 188 = 0.36849
Mean Absolute Error for User 189 = 0.27754
Mean Absolute Error for User 190 = 0.45612
Mean Absolute Error for User 191 = 0.42039
Mean Absolute Error for User 192 = 0.54582
Mean Absolute Error for User 193 = 0.54827
Mean Absolute Error for User 194 = 0.32368
Mean Absolute Error for User 195 = 0.55261
Mean Absolute Error for User 196 = 0.46521
Mean Absolute Error for User 197 = 0.57783
Mean Absolute Error for User 198 = 0.59197
Mean Absolute Error for User 199 = 0.59708
Mean Absolute Error for User 200 = 0.51953
Mean Absolute Error for User 201 = 0.48267
Mean Absolute Error for User 202 = 0.43941
Mean Absolute Error for User 203 = 0.60807
Mean Absolute Error for User 204 = 0.31232
Mean Absolute Error for User 205 = 0.42905
Mean Absolute Error for User 206 = 0.44299
Mean Absolute Error for User 207 = 0.28905
Mean Absolute Error for User 208 = 0.44267
Mean Absolute Error for User 209 = 0.32186
Mean Absolute Error for User 210 = 0.35296
Mean Absolute Error for User 211 = 0.39991
Mean Absolute Error for User 212 = 0.43607
Mean Absolute Error for User 213 = 0.33458
Mean Absolute Error for User 214 = 0.29073
Mean Absolute Error for User 215 = 0.44065
Mean Absolute Error for User 216 = 0.55502
Mean Absolute Error for User 217 = 0.52949
Mean Absolute Error for User 218 = 0.35465
Mean Absolute Error for User 219 = 0.57498
Mean Absolute Error for User 220 = 0.47669
Mean Absolute Error for User 221 = 0.41576
Mean Absolute Error for User 222 = 0.52883
Mean Absolute Error for User 223 = 0.53094
Mean Absolute Error for User 224 = 0.44909
Mean Absolute Error for User 225 = 0.48615
Mean Absolute Error for User 226 = 0.51203
Mean Absolute Error for User 227 = 0.41728
Mean Absolute Error for User 228 = 0.42328
Mean Absolute Error for User 229 = 0.43490
Mean Absolute Error for User 230 = 0.66380
Mean Absolute Error for User 231 = 0.52845
Mean Absolute Error for User 232 = 0.41051
Mean Absolute Error for User 233 = 0.41850
Mean Absolute Error for User 234 = 0.59951
Mean Absolute Error for User 235 = 0.44948
Mean Absolute Error for User 236 = 0.21808
Mean Absolute Error for User 237 = 0.48923
Mean Absolute Error for User 238 = 0.41346
Mean Absolute Error for User 239 = 0.44998
Mean Absolute Error for User 240 = 0.59334
Mean Absolute Error for User 241 = 0.43436
Mean Absolute Error for User 242 = 0.60076
Mean Absolute Error for User 243 = 0.51204
Mean Absolute Error for User 244 = 0.58313
Mean Absolute Error for User 245 = 0.32410
Mean Absolute Error for User 246 = 0.47404
Mean Absolute Error for User 247 = 0.57216
Mean Absolute Error for User 248 = 0.35671
Mean Absolute Error for User 249 = 0.32635
Mean Absolute Error for User 250 = 0.38636
Mean Absolute Error for User 251 = 0.23032
Mean Absolute Error for User 252 = 0.40081
Mean Absolute Error for User 253 = 0.34493
Mean Absolute Error for User 254 = 0.42063
Mean Absolute Error for User 255 = 0.37251
Mean Absolute Error for User 256 = 0.40641
Mean Absolute Error for User 257 = 0.50516
Mean Absolute Error for User 258 = 0.29910
Mean Absolute Error for User 259 = 0.47383
Mean Absolute Error for User 260 = 0.54408
Mean Absolute Error for User 261 = 0.42307
Mean Absolute Error for User 262 = 0.59533
Mean Absolute Error for User 263 = 0.46069
Mean Absolute Error for User 264 = 0.64261
Mean Absolute Error for User 265 = 0.52136
Mean Absolute Error for User 266 = 0.69348
Mean Absolute Error for User 267 = 0.57409
Mean Absolute Error for User 268 = 0.50003
Mean Absolute Error for User 269 = 0.34076
Mean Absolute Error for User 270 = 0.48449
Mean Absolute Error for User 271 = 0.33565
Mean Absolute Error for User 272 = 0.38457
Mean Absolute Error for User 273 = 0.57582
Mean Absolute Error for User 274 = 0.46276
Mean Absolute Error for User 275 = 0.57774
Mean Absolute Error for User 276 = 0.39964
Mean Absolute Error for User 277 = 0.47883
Mean Absolute Error for User 278 = 0.36676
Mean Absolute Error for User 279 = 0.53020
Mean Absolute Error for User 280 = 0.42746
Mean Absolute Error for User 281 = 0.39518
Mean Absolute Error for User 282 = 0.42710
Mean Absolute Error for User 283 = 0.50753
Mean Absolute Error for User 284 = 0.61140
Mean Absolute Error for User 285 = 0.33473
Mean Absolute Error for User 286 = 0.56946
Mean Absolute Error for User 287 = 0.50727
Mean Absolute Error for User 288 = 0.49915
Mean Absolute Error for User 289 = 0.37977
Mean Absolute Error for User 290 = 0.36882
Mean Absolute Error for User 291 = 0.31624
Mean Absolute Error for User 292 = 0.44731
Mean Absolute Error for User 293 = 0.39097
Mean Absolute Error for User 294 = 0.53840
Mean Absolute Error for User 295 = 0.54422
Mean Absolute Error for User 296 = 0.19625
Mean Absolute Error for User 297 = 0.49363
Mean Absolute Error for User 298 = 0.55579
Mean Absolute Error for User 299 = 0.36414
Mean Absolute Error for User 300 = 0.39649
Mean Absolute Error for User 301 = 0.61959
Mean Absolute Error for User 302 = 0.41492
Mean Absolute Error for User 303 = 0.57346
Mean Absolute Error for User 304 = 0.57527
Mean Absolute Error for User 305 = 0.55528
Mean Absolute Error for User 306 = 0.38539
Mean Absolute Error for User 307 = 0.52181
Mean Absolute Error for User 308 = 0.63032
Mean Absolute Error for User 309 = 0.39445
Mean Absolute Error for User 310 = 0.36501
Mean Absolute Error for User 311 = 0.28853
Mean Absolute Error for User 312 = 0.42057
Mean Absolute Error for User 313 = 0.53288
Mean Absolute Error for User 314 = 0.57206
Mean Absolute Error for User 315 = 0.33786
Mean Absolute Error for User 316 = 0.49839
Mean Absolute Error for User 317 = 0.59117
Mean Absolute Error for User 318 = 0.32326
Mean Absolute Error for User 319 = 0.39401
Mean Absolute Error for User 320 = 0.26832
Mean Absolute Error for User 321 = 0.51898
Mean Absolute Error for User 322 = 0.55418
Mean Absolute Error for User 323 = 0.48382
Mean Absolute Error for User 324 = 0.32456
Mean Absolute Error for User 325 = 0.44180
Mean Absolute Error for User 326 = 0.48965
Mean Absolute Error for User 327 = 0.36717
Mean Absolute Error for User 328 = 0.68555
Mean Absolute Error for User 329 = 0.27781
Mean Absolute Error for User 330 = 0.65830
Mean Absolute Error for User 331 = 0.56582
Mean Absolute Error for User 332 = 0.40534
Mean Absolute Error for User 333 = 0.36120
Mean Absolute Error for User 334 = 0.35269
Mean Absolute Error for User 335 = 0.54834
Mean Absolute Error for User 336 = 0.44366
Mean Absolute Error for User 337 = 0.45182
Mean Absolute Error for User 338 = 0.30177
Mean Absolute Error for User 339 = 0.50255
Mean Absolute Error for User 340 = 0.40911
Mean Absolute Error for User 341 = 0.48392
Mean Absolute Error for User 342 = 0.39201
Mean Absolute Error for User 343 = 0.51550
Mean Absolute Error for User 344 = 0.51695
Mean Absolute Error for User 345 = 0.34973
Mean Absolute Error for User 346 = 0.39946
Mean Absolute Error for User 347 = 0.44815
Mean Absolute Error for User 348 = 0.28745
Mean Absolute Error for User 349 = 0.50566
Mean Absolute Error for User 350 = 0.37915
Mean Absolute Error for User 351 = 0.36681
Mean Absolute Error for User 352 = 0.53125
Mean Absolute Error for User 353 = 0.54011
Mean Absolute Error for User 354 = 0.36057
Mean Absolute Error for User 355 = 0.41940
Mean Absolute Error for User 356 = 0.52210
Mean Absolute Error for User 357 = 0.44017
Mean Absolute Error for User 358 = 0.34369
Mean Absolute Error for User 359 = 0.58001
Mean Absolute Error for User 360 = 0.26018
Mean Absolute Error for User 361 = 0.43198
Mean Absolute Error for User 362 = 0.37349
Mean Absolute Error for User 363 = 0.40900
Mean Absolute Error for User 364 = 0.49013
Mean Absolute Error for User 365 = 0.53640
Mean Absolute Error for User 366 = 0.24993
Mean Absolute Error for User 367 = 0.48893
Mean Absolute Error for User 368 = 0.44530
Mean Absolute Error for User 369 = 0.49444
Mean Absolute Error for User 370 = 0.52800
Mean Absolute Error for User 371 = 0.36661
Mean Absolute Error for User 372 = 0.55299
Mean Absolute Error for User 373 = 0.57520
Mean Absolute Error for User 374 = 0.53162
Mean Absolute Error for User 375 = 0.54958
Mean Absolute Error for User 376 = 0.50581
Mean Absolute Error for User 377 = 0.27071
Mean Absolute Error for User 378 = 0.38554
Mean Absolute Error for User 379 = 0.65513
Mean Absolute Error for User 380 = 0.53298
Mean Absolute Error for User 381 = 0.51433
Mean Absolute Error for User 382 = 0.35088
Mean Absolute Error for User 383 = 0.45256
Mean Absolute Error for User 384 = 0.40639
Mean Absolute Error for User 385 = 0.50865
Mean Absolute Error for User 386 = 0.54193
Mean Absolute Error for User 387 = 0.41058
Mean Absolute Error for User 388 = 0.17128
Mean Absolute Error for User 389 = 0.54601
Mean Absolute Error for User 390 = 0.45476
Mean Absolute Error for User 391 = 0.58739
Mean Absolute Error for User 392 = 0.37805
Mean Absolute Error for User 393 = 0.32743
Mean Absolute Error for User 394 = 0.56712
Mean Absolute Error for User 395 = 0.43139
Mean Absolute Error for User 396 = 0.59416
Mean Absolute Error for User 397 = 0.37385
Mean Absolute Error for User 398 = 0.28986
Mean Absolute Error for User 399 = 0.62370
Mean Absolute Error for User 400 = 0.34588
Mean Absolute Error for User 401 = 0.42339
Mean Absolute Error for User 402 = 0.51942
Mean Absolute Error for User 403 = 0.42984
Mean Absolute Error for User 404 = 0.38938
Mean Absolute Error for User 405 = 0.34086
Mean Absolute Error for User 406 = 0.26775
Mean Absolute Error for User 407 = 0.39563
Mean Absolute Error for User 408 = 0.45450
Mean Absolute Error for User 409 = 0.54026
Mean Absolute Error for User 410 = 0.48819
Mean Absolute Error for User 411 = 0.53379
Mean Absolute Error for User 412 = 0.59230
Mean Absolute Error for User 413 = 0.61736
Mean Absolute Error for User 414 = 0.45411
Mean Absolute Error for User 415 = 0.31816
Mean Absolute Error for User 416 = 0.44262
Mean Absolute Error for User 417 = 0.45161
Mean Absolute Error for User 418 = 0.44287
Mean Absolute Error for User 419 = 0.51469
Mean Absolute Error for User 420 = 0.33909
Mean Absolute Error for User 421 = 0.33957
Mean Absolute Error for User 422 = 0.45176
Mean Absolute Error for User 423 = 0.38575
Mean Absolute Error for User 424 = 0.53764
Mean Absolute Error for User 425 = 0.39147
Mean Absolute Error for User 426 = 0.59500
Mean Absolute Error for User 427 = 0.46086
Mean Absolute Error for User 428 = 0.55747
Mean Absolute Error for User 429 = 0.41603
Mean Absolute Error for User 430 = 0.58882
Mean Absolute Error for User 431 = 0.31713
Mean Absolute Error for User 432 = 0.50735
Mean Absolute Error for User 433 = 0.53492
Mean Absolute Error for User 434 = 0.49295
Mean Absolute Error for User 435 = 0.37689
Mean Absolute Error for User 436 = 0.41798
Mean Absolute Error for User 437 = 0.57839
Mean Absolute Error for User 438 = 0.44636
Mean Absolute Error for User 439 = 0.42286
Mean Absolute Error for User 440 = 0.34839
Mean Absolute Error for User 441 = 0.41129
Mean Absolute Error for User 442 = 0.40579
Mean Absolute Error for User 443 = 0.47866
Mean Absolute Error for User 444 = 0.43044
Mean Absolute Error for User 445 = 0.57067
Mean Absolute Error for User 446 = 0.54258
Mean Absolute Error for User 447 = 0.59059
Mean Absolute Error for User 448 = 0.44352
Mean Absolute Error for User 449 = 0.43077
Mean Absolute Error for User 450 = 0.34942
Mean Absolute Error for User 451 = 0.41998
Mean Absolute Error for User 452 = 0.44580
Mean Absolute Error for User 453 = 0.60387
Mean Absolute Error for User 454 = 0.41100
Mean Absolute Error for User 455 = 0.43562
Mean Absolute Error for User 456 = 0.49035
Mean Absolute Error for User 457 = 0.58979
Mean Absolute Error for User 458 = 0.55299
Mean Absolute Error for User 459 = 0.44551
Mean Absolute Error for User 460 = 0.33912
Mean Absolute Error for User 461 = 0.49579
Mean Absolute Error for User 462 = 0.48168
Mean Absolute Error for User 463 = 0.41202
Mean Absolute Error for User 464 = 0.59692
Mean Absolute Error for User 465 = 0.38891
Mean Absolute Error for User 466 = 0.41185
Mean Absolute Error for User 467 = 0.63584
Mean Absolute Error for User 468 = 0.63752
Mean Absolute Error for User 469 = 0.52033
Mean Absolute Error for User 470 = 0.46500
Mean Absolute Error for User 471 = 0.38674
Mean Absolute Error for User 472 = 0.46219
Mean Absolute Error for User 473 = 0.42046
Mean Absolute Error for User 474 = 0.42128
Mean Absolute Error for User 475 = 0.43971
Mean Absolute Error for User 476 = 0.41842
Mean Absolute Error for User 477 = 0.46796
Mean Absolute Error for User 478 = 0.42756
Mean Absolute Error for User 479 = 0.48408
Mean Absolute Error for User 480 = 0.58848
Mean Absolute Error for User 481 = 0.44679
Mean Absolute Error for User 482 = 0.41788
Mean Absolute Error for User 483 = 0.51781
Mean Absolute Error for User 484 = 0.51129
Mean Absolute Error for User 485 = 0.47048
Mean Absolute Error for User 486 = 0.63711
Mean Absolute Error for User 487 = 0.52917
Mean Absolute Error for User 488 = 0.45911
Mean Absolute Error for User 489 = 0.57219
Mean Absolute Error for User 490 = 0.28634
Mean Absolute Error for User 491 = 0.41687
Mean Absolute Error for User 492 = 0.39503
Mean Absolute Error for User 493 = 0.47855
Mean Absolute Error for User 494 = 0.42385
Mean Absolute Error for User 495 = 0.63967
Mean Absolute Error for User 496 = 0.33175
Mean Absolute Error for User 497 = 0.59860
Mean Absolute Error for User 498 = 0.56403
Mean Absolute Error for User 499 = 0.32326
Mean Absolute Error for User 500 = 0.62265
Mean Absolute Error for User 501 = 0.55609
Mean Absolute Error for User 502 = 0.34451
Mean Absolute Error for User 503 = 0.40629
Mean Absolute Error for User 504 = 0.32432
Mean Absolute Error for User 505 = 0.42850
Mean Absolute Error for User 506 = 0.43842
Mean Absolute Error for User 507 = 0.43870
Mean Absolute Error for User 508 = 0.57140
Mean Absolute Error for User 509 = 0.36828
Mean Absolute Error for User 510 = 0.48599
Mean Absolute Error for User 511 = 0.29497
Mean Absolute Error for User 512 = 0.49734
Mean Absolute Error for User 513 = 0.41794
Mean Absolute Error for User 514 = 0.40898
Mean Absolute Error for User 515 = 0.18215
Mean Absolute Error for User 516 = 0.34591
Mean Absolute Error for User 517 = 0.42345
Mean Absolute Error for User 518 = 0.31383
Mean Absolute Error for User 519 = 0.41972
Mean Absolute Error for User 520 = 0.53147
Mean Absolute Error for User 521 = 0.30729
Mean Absolute Error for User 522 = 0.62009
Mean Absolute Error for User 523 = 0.32031
Mean Absolute Error for User 524 = 0.67072
Mean Absolute Error for User 525 = 0.44143
Mean Absolute Error for User 526 = 0.39146
Mean Absolute Error for User 527 = 0.50478
Mean Absolute Error for User 528 = 0.45981
Mean Absolute Error for User 529 = 0.52848
Mean Absolute Error for User 530 = 0.45032
Mean Absolute Error for User 531 = 0.57220
Mean Absolute Error for User 532 = 0.45099
Mean Absolute Error for User 533 = 0.41334
Mean Absolute Error for User 534 = 0.45999
Mean Absolute Error for User 535 = 0.33084
Mean Absolute Error for User 536 = 0.44983
Mean Absolute Error for User 537 = 0.43529
Mean Absolute Error for User 538 = 0.37640
Mean Absolute Error for User 539 = 0.45871
Mean Absolute Error for User 540 = 0.29194
Mean Absolute Error for User 541 = 0.64693
Mean Absolute Error for User 542 = 0.64408
Mean Absolute Error for User 543 = 0.35599
Mean Absolute Error for User 544 = 0.35979
Mean Absolute Error for User 545 = 0.39908
Mean Absolute Error for User 546 = 0.27416
Mean Absolute Error for User 547 = 0.28548
Mean Absolute Error for User 548 = 0.40584
Mean Absolute Error for User 549 = 0.47340
Mean Absolute Error for User 550 = 0.27882
Mean Absolute Error for User 551 = 0.45715
Mean Absolute Error for User 552 = 0.49566
Mean Absolute Error for User 553 = 0.36844
Mean Absolute Error for User 554 = 0.41415
Mean Absolute Error for User 555 = 0.57123
Mean Absolute Error for User 556 = 0.32220
Mean Absolute Error for User 557 = 0.49812
Mean Absolute Error for User 558 = 0.29997
Mean Absolute Error for User 559 = 0.50388
Mean Absolute Error for User 560 = 0.36512
Mean Absolute Error for User 561 = 0.50110
Mean Absolute Error for User 562 = 0.46121
Mean Absolute Error for User 563 = 0.38798
Mean Absolute Error for User 564 = 0.42287
Mean Absolute Error for User 565 = 0.45592
Mean Absolute Error for User 566 = 0.68340
Mean Absolute Error for User 567 = 0.35275
Mean Absolute Error for User 568 = 0.29250
Mean Absolute Error for User 569 = 0.53636
Mean Absolute Error for User 570 = 0.39292
Mean Absolute Error for User 571 = 0.28196
Mean Absolute Error for User 572 = 0.51115
Mean Absolute Error for User 573 = 0.51699
Mean Absolute Error for User 574 = 0.49973
Mean Absolute Error for User 575 = 0.18942
Mean Absolute Error for User 576 = 0.42376
Mean Absolute Error for User 577 = 0.56911
Mean Absolute Error for User 578 = 0.19103
Mean Absolute Error for User 579 = 0.56233
Mean Absolute Error for User 580 = 0.57826
Mean Absolute Error for User 581 = 0.36228
Mean Absolute Error for User 582 = 0.38154
Mean Absolute Error for User 583 = 0.46012
Mean Absolute Error for User 584 = 0.46740
Mean Absolute Error for User 585 = 0.36875
Mean Absolute Error for User 586 = 0.41972
Mean Absolute Error for User 587 = 0.50404
Mean Absolute Error for User 588 = 0.54809
Mean Absolute Error for User 589 = 0.51779
Mean Absolute Error for User 590 = 0.40379
Mean Absolute Error for User 591 = 0.61093
Mean Absolute Error for User 592 = 0.60336
Mean Absolute Error for User 593 = 0.66956
Mean Absolute Error for User 594 = 0.32834
Mean Absolute Error for User 595 = 0.38174
Mean Absolute Error for User 596 = 0.37546
Mean Absolute Error for User 597 = 0.58286
Mean Absolute Error for User 598 = 0.29747
Mean Absolute Error for User 599 = 0.39020
Mean Absolute Error for User 600 = 0.58259
Mean Absolute Error for User 601 = 0.33255
Mean Absolute Error for User 602 = 0.62931
Mean Absolute Error for User 603 = 0.49534
Mean Absolute Error for User 604 = 0.51340
Mean Absolute Error for User 605 = 0.44110
Mean Absolute Error for User 606 = 0.34879
Mean Absolute Error for User 607 = 0.63261
Mean Absolute Error for User 608 = 0.65458
Mean Absolute Error for User 609 = 0.28497
Mean Absolute Error for User 610 = 0.34489
Overall Mean Absolute Error = 0.47243
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4>Step5.show recommended movie list for a certain user</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_recommended_top_unrated</span><span class="p">(</span><span class="n">predicted_df</span><span class="p">,</span> <span class="n">did_rating_df</span><span class="p">,</span> <span class="n">ratings_mean_df</span><span class="p">,</span> <span class="n">movies_df</span><span class="p">,</span> <span class="n">userId</span><span class="p">,</span> <span class="n">num</span><span class="p">):</span>
    <span class="nb">list</span><span class="o">=</span><span class="p">[]</span>
    <span class="n">count</span><span class="o">=</span><span class="mi">0</span>
    <span class="n">user_rating</span> <span class="o">=</span> <span class="n">predicted_ratings_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="n">userId</span><span class="p">]</span>
    <span class="n">user_rating_sort</span><span class="o">=</span><span class="n">user_rating</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">user_rating_sort</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span><span class="p">(</span><span class="n">did_rating_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">index</span><span class="p">,</span><span class="n">userId</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">):</span>
            <span class="nb">list</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">index</span><span class="p">,</span><span class="n">value</span><span class="p">,</span><span class="n">ratings_mean_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">index</span><span class="p">,</span><span class="mi">0</span><span class="p">]))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;movie name: &quot;</span><span class="p">,</span><span class="n">movies_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">index</span><span class="p">,</span><span class="s2">&quot;title&quot;</span><span class="p">],</span>
                  <span class="s2">&quot; pred rating: </span><span class="si">%.3f</span><span class="s2"> &quot;</span><span class="o">%</span><span class="k">value</span>, &quot; mean rating: %.3f &quot;%ratings_mean_df.loc[index,0])
            <span class="n">count</span><span class="o">+=</span><span class="mi">1</span>
            <span class="k">if</span><span class="p">(</span><span class="n">count</span><span class="o">==</span><span class="n">num</span><span class="p">):</span>
                <span class="k">break</span>
    <span class="k">return</span> <span class="nb">list</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">did_rating_df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">did_ratings_arr</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="n">movie_index</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="n">user_header</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#As you can see, predicted ratings can be higher than 5, which means it&#39;s predicted that the user</span>
<span class="c1"># may give a very high score. </span>
<span class="nb">list</span><span class="o">=</span><span class="n">get_recommended_top_unrated</span><span class="p">(</span><span class="n">predicted_ratings_df</span><span class="p">,</span><span class="n">did_rating_df</span><span class="p">,</span><span class="n">ratings_mean_df</span><span class="p">,</span><span class="n">movies_df</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>movie name:  Prime Suspect 2 (1992)  pred rating: 9.910   mean rating: 3.000 
movie name:  Beer League (2006)  pred rating: 8.922   mean rating: 4.000 
movie name:  There Will Come a Day (2013)  pred rating: 8.860   mean rating: 3.500 
movie name:  Times of Harvey Milk, The (1984)  pred rating: 8.811   mean rating: 4.500 
movie name:  Tyler Perry&#39;s I Can Do Bad All by Myself (2009)  pred rating: 8.789   mean rating: 5.000 
movie name:  Act of Killing, The (2012)  pred rating: 8.678   mean rating: 5.000 
movie name:  Son of the Bride (Hijo de la novia, El) (2001)  pred rating: 8.640   mean rating: 5.000 
movie name:  Made in Dagenham (2010)  pred rating: 8.611   mean rating: 2.000 
movie name:  The Wait (2015)  pred rating: 8.578   mean rating: 3.500 
movie name:  Legend of 1900, The (a.k.a. The Legend of the Pianist on the Ocean) (Leggenda del pianista sull&#39;oceano) (1998)  pred rating: 8.554   mean rating: 3.667 
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>end</h3>
</div>
</div>
</div>
    </div>
  </div>


 



<script type="text/javascript" src="/d2l/common/math/MathML.js?v=20.20.5.22012-324 "></script><script type="text/javascript">document.addEventListener('DOMContentLoaded', function() { D2LMathML.DesktopInit('https://s.brightspace.com/lib/mathjax/2.7.4/MathJax.js?config=MML_HTMLorMML','https://s.brightspace.com/lib/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML','130'); });</script></body></html>